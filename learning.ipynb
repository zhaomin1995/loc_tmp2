{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from utils import preprocess\n",
    "from utils import learning_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/annotations/new_annot.json'\n",
    "mode = 'anchor_text_only'\n",
    "\n",
    "instances = preprocess.load_data(data_dir, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for BERT: 0m 40s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "instances = preprocess.add_bert_output(instances, anchor_only=True)\n",
    "end_time = time.time()\n",
    "elapsed_mins, elapsed_secs = learning_helper.epoch_time(start_time, end_time)\n",
    "print(f\"Time spent for BERT: {elapsed_mins}m {elapsed_secs}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhaomin/envs/torch/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for VGG: 1m 13s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "instances = preprocess.add_vgg_output(instances, anchor_only=True)\n",
    "end_time = time.time()\n",
    "elapsed_mins, elapsed_secs = learning_helper.epoch_time(start_time, end_time)\n",
    "print(f\"Time spent for VGG: {elapsed_mins}m {elapsed_secs}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instances, dev_instances, test_instances = preprocess.split_instances(instances)\n",
    "train_loader, dev_loader, test_loader = preprocess.get_data_loader(train_instances, dev_instances, test_instances, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model.anchor_text_only import AnchorTextOnlyModel\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = AnchorTextOnlyModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnchorTextOnlyModel(\n",
       "  (fc1): Linear(in_features=768, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Epoch: 1 || Epoch Time: 0m 0s\n",
      "Epoch: 1 || Train loss: 0.04, Train Acc: 0.68\n",
      "Epoch: 1 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "------------------------------------------------------------\n",
      "Epoch: 2 || Epoch Time: 0m 0s\n",
      "Epoch: 2 || Train loss: 0.04, Train Acc: 0.68\n",
      "Epoch: 2 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "------------------------------------------------------------\n",
      "Epoch: 3 || Epoch Time: 0m 0s\n",
      "Epoch: 3 || Train loss: 0.04, Train Acc: 0.68\n",
      "Epoch: 3 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "------------------------------------------------------------\n",
      "Epoch: 4 || Epoch Time: 0m 0s\n",
      "Epoch: 4 || Train loss: 0.04, Train Acc: 0.68\n",
      "Epoch: 4 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "------------------------------------------------------------\n",
      "Epoch: 5 || Epoch Time: 0m 0s\n",
      "Epoch: 5 || Train loss: 0.04, Train Acc: 0.68\n",
      "Epoch: 5 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "------------------------------------------------------------\n",
      "Epoch: 6 || Epoch Time: 0m 0s\n",
      "Epoch: 6 || Train loss: 0.04, Train Acc: 0.68\n",
      "Epoch: 6 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "------------------------------------------------------------\n",
      "Epoch: 7 || Epoch Time: 0m 0s\n",
      "Epoch: 7 || Train loss: 0.04, Train Acc: 0.68\n",
      "Epoch: 7 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 8 || Epoch Time: 0m 0s\n",
      "Epoch: 8 || Train loss: 0.04, Train Acc: 0.68\n",
      "Epoch: 8 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "------------------------------------------------------------\n",
      "Epoch: 9 || Epoch Time: 0m 0s\n",
      "Epoch: 9 || Train loss: 0.04, Train Acc: 0.68\n",
      "Epoch: 9 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "------------------------------------------------------------\n",
      "Epoch: 10 || Epoch Time: 0m 0s\n",
      "Epoch: 10 || Train loss: 0.04, Train Acc: 0.68\n",
      "Epoch: 10 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "------------------------------------------------------------\n",
      "Epoch: 11 || Epoch Time: 0m 0s\n",
      "Epoch: 11 || Train loss: 0.04, Train Acc: 0.68\n",
      "Epoch: 11 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 12 || Epoch Time: 0m 0s\n",
      "Epoch: 12 || Train loss: 0.04, Train Acc: 0.68\n",
      "Epoch: 12 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 13 || Epoch Time: 0m 0s\n",
      "Epoch: 13 || Train loss: 0.04, Train Acc: 0.68\n",
      "Epoch: 13 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 14 || Epoch Time: 0m 0s\n",
      "Epoch: 14 || Train loss: 0.04, Train Acc: 0.68\n",
      "Epoch: 14 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 15 || Epoch Time: 0m 0s\n",
      "Epoch: 15 || Train loss: 0.04, Train Acc: 0.68\n",
      "Epoch: 15 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "The loss on development set does not decrease, stop training!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-04)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "label_to_idx = {'Yes': 1, 'No': 0}\n",
    "idx_to_label = {1: 'Yes', 0: 'No'}\n",
    "    \n",
    "num_epochs = 100\n",
    "patience = 5\n",
    "best_valid_loss = float('inf')\n",
    "check_stopping = 0\n",
    "model_name = f'retrained_{mode}_classifier.pkl'\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc = learning_helper.train(model, train_loader, optimizer, criterion, device, label_to_idx)\n",
    "    dev_loss, dev_acc = learning_helper.evaluate(model, dev_loader, criterion, device, label_to_idx)\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_mins, elapsed_secs = learning_helper.epoch_time(start_time, end_time)\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Epoch: {i+1} || Epoch Time: {elapsed_mins}m {elapsed_secs}s\")\n",
    "    print(f\"Epoch: {i+1} || Train loss: {train_loss:.02f}, Train Acc: {train_acc:.02f}\")\n",
    "    print(f\"Epoch: {i+1} || Dev loss: {dev_loss:.02f}, Dev Acc: {dev_acc:.02f}\")\n",
    "\n",
    "    # check if we need to save the model\n",
    "    if dev_loss < best_valid_loss:\n",
    "        check_stopping = 0\n",
    "        best_valid_loss = dev_loss\n",
    "        torch.save(model, model_name)\n",
    "    else:\n",
    "        check_stopping += 1\n",
    "        print(f\"The loss on development set does not decrease\")\n",
    "        if check_stopping == patience:\n",
    "            print(\"The loss on development set does not decrease, stop training!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0+cu101\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add more info to the annotation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "annotation_filepath = 'data/annotations/annotation_context.json'\n",
    "original_batch_filepath = 'batch_6540.csv'\n",
    "data_dir = 'data'\n",
    "\n",
    "lookup_dict = defaultdict(dict)\n",
    "with open(original_batch_filepath, 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        lookup_dict[row['instance_id']] = row\n",
    "        \n",
    "def add_info(lookup_dict, annotation_filepath):\n",
    "    instances = []\n",
    "    with open(annotation_filepath, 'r') as jsonfile:\n",
    "        lines = jsonfile.read().split(\"\\n\")[:-1]\n",
    "        for line in lines:\n",
    "            instance = {}\n",
    "            temp_instance = json.loads(line)\n",
    "            # remove \"Input.\" in the keys\n",
    "            for key, value in temp_instance.items():\n",
    "                if key.startswith(\"Input.\"):\n",
    "                    if not key.endswith(\"url\"):\n",
    "                        newkey = key.split(\".\")[-1]\n",
    "                        instance[newkey] = value\n",
    "                else:\n",
    "                    instance[key] = value\n",
    "\n",
    "            # add image filepath, json filepath, screenshot url, tweet_text, and timestamp\n",
    "            original_dict = lookup_dict[temp_instance['Input.instance_id']]\n",
    "            for key, value in original_dict.items():\n",
    "                if key.endswith(\"url\"):\n",
    "                    tweet_id = value.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0]\n",
    "\n",
    "                    # add json filepath\n",
    "                    jsonname = f\"anchor_{tweet_id}.json\" if 'anchor' in key else f\"{tweet_id}.json\"\n",
    "                    jsonpath = os.path.join(data_dir, 'json_files', '_'.join(value.split(\"/\")[-1].split(\"_\")[:2]), jsonname)\n",
    "                    jsonkey = key.split(\"_\")[0] + \"_jsonpath\"\n",
    "                    instance[jsonkey] = jsonpath\n",
    "\n",
    "                    # add tweet text\n",
    "                    with open(jsonpath, 'r') as tweetfile:\n",
    "                        tweet = json.loads(tweetfile.read())\n",
    "                    textkey = key.split(\"_\")[0] + \"_tweettext\"\n",
    "                    instance[textkey] = tweet['full_text']\n",
    "\n",
    "                    # add image filepath if image exists\n",
    "                    instance[key] = value\n",
    "                    imagename = f\"anchor_{tweet_id}.jpg\" if 'anchor' in key else f\"{tweet_id}.jpg\"\n",
    "                    imagepath = os.path.join(data_dir, 'image_files', '_'.join(value.split(\"/\")[-1].split(\"_\")[:2]), imagename)\n",
    "                    hasimg = os.path.isfile(imagepath)\n",
    "                    if hasimg:\n",
    "                        imagekey = key.split(\"_\")[0] + \"_imagepath\"\n",
    "                        instance[imagekey] = imagepath\n",
    "\n",
    "                if key.endswith(\"timestamp\"):\n",
    "                    instance[key] = original_dict[key]\n",
    "            instances.append(instance)\n",
    "    return instances\n",
    "\n",
    "instances = add_info(lookup_dict, annotation_filepath)\n",
    "\n",
    "new_annot_filename = 'new_annot.json'\n",
    "with open(new_annot_filename, 'w') as newjson:\n",
    "    for instance in instances:\n",
    "        newjson.write(json.dumps(instance))\n",
    "        newjson.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## copy the json file and image file to the loctmp2 folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import os\n",
    "from shutil import copyfile\n",
    "\n",
    "original_folder = '/media/zhaomin/Zhaomin_SSD/project_repo/emnlp2021/saved_tweets_original'\n",
    "data_dir = 'data'\n",
    "\n",
    "original_batch_filepath = 'batch_6540.csv'\n",
    "lookup_dict = defaultdict(dict)\n",
    "with open(original_batch_filepath, 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        lookup_dict[row['instance_id']] = row\n",
    "        \n",
    "annotation_filepath = 'data/annotations/annotation_context.json'\n",
    "with open(annotation_filepath, 'r') as jsonfile:\n",
    "    lines = jsonfile.read().split(\"\\n\")[:-1]\n",
    "    for line in lines:\n",
    "        instance = json.loads(line)\n",
    "        instance_id = instance['Input.instance_id']\n",
    "        \n",
    "        # create folder if it does not exist\n",
    "        if not os.path.isdir(os.path.join(data_dir, 'json_files', instance_id)):\n",
    "            os.mkdir(os.path.join(data_dir, 'json_files', instance_id))\n",
    "        if not os.path.isdir(os.path.join(data_dir, 'image_files', instance_id)):\n",
    "            os.mkdir(os.path.join(data_dir, 'image_files', instance_id))\n",
    "            \n",
    "        # find event path\n",
    "        original_dict = lookup_dict[instance_id]\n",
    "        event_name = re.split('(\\d+)', instance_id.split(\"_\")[0])[0]\n",
    "        for original_event in os.listdir(original_folder):\n",
    "            \n",
    "            # make sure the event and year are matched\n",
    "            if original_event.split(\"_\")[0] == event_name:\n",
    "                if original_event.split(\"_\")[1].split(\"-\")[0] == re.split('(\\d+)', instance_id.split(\"_\")[0])[1]:\n",
    "                    original_event_path = os.path.join(original_folder, original_event, f\"final_tweet_folder_{original_event}\", instance_id.split(\"_\")[-1])\n",
    "                    break\n",
    "        \n",
    "        for key, value in original_dict.items():\n",
    "            if key.endswith(\"url\"):\n",
    "                \n",
    "                if 'anchor' in key:\n",
    "                    real_instance_id = value.split(\"/\")[-1].split(\"_\")[1]\n",
    "                    src_jsonfilename = f\"anchor_{real_instance_id}.json\"\n",
    "                    src_imagefilename = f\"anchor_{real_instance_id}.jpg\"\n",
    "                    src_jsonfilepath = os.path.join(original_event_path, src_jsonfilename)\n",
    "                    src_imagefilepath = os.path.join(original_event_path, src_imagefilename)\n",
    "                    dst_jsonfilepath = os.path.join(data_dir, 'json_files', instance_id, src_jsonfilename)\n",
    "                    dst_imagefilepath = os.path.join(data_dir, 'image_files', instance_id, src_imagefilename)\n",
    "                    copyfile(src_jsonfilepath, dst_jsonfilepath)\n",
    "                    copyfile(src_imagefilepath, dst_imagefilepath)\n",
    "                \n",
    "                else:\n",
    "                    tweet_id = value.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1]\n",
    "                    \n",
    "                    # copy json file\n",
    "                    src_jsonfilename = f\"{tweet_id}.json\"\n",
    "                    src_jsonfilepath = os.path.join(original_event_path, src_jsonfilename)\n",
    "                    dst_jsonfilepath = os.path.join(data_dir, 'json_files', instance_id, src_jsonfilename)\n",
    "                    copyfile(src_jsonfilepath, dst_jsonfilepath)\n",
    "                    \n",
    "                    # copy image file if it exists\n",
    "                    src_imagefilename = f\"{tweet_id}.jpg\"\n",
    "                    if src_imagefilename in os.listdir(original_event_path):\n",
    "                        src_imagefilepath = os.path.join(original_event_path, src_imagefilename)\n",
    "                        dst_imagefilepath = os.path.join(data_dir, 'image_files', instance_id, src_imagefilename)\n",
    "                        copyfile(src_imagefilepath, dst_imagefilepath)\n",
    "                    \n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save split for replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = instances\n",
    "y = [x['adjudicated_label'] for x in instances]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y)\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, test_size=0.20, stratify=y_train)\n",
    "\n",
    "split = {'train': [x['instance_id'] for x in X_train],\n",
    "         'dev': [x['instance_id'] for x in X_dev],\n",
    "         'test': [x['instance_id'] for x in X_test]}\n",
    "\n",
    "with open(\"saved_split\", 'w') as splitfile:\n",
    "    splitfile.write(json.dumps(split))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
