{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from utils import preprocess\n",
    "from utils import learning_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/annotations/new_annot.json'\n",
    "mode = 'anchor_text_image'\n",
    "\n",
    "instances = preprocess.load_data(data_dir, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for BERT: 0m 41s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "instances = preprocess.add_bert_output(instances, anchor_only=True)\n",
    "end_time = time.time()\n",
    "elapsed_mins, elapsed_secs = learning_helper.epoch_time(start_time, end_time)\n",
    "print(f\"Time spent for BERT: {elapsed_mins}m {elapsed_secs}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhaomin/envs/torch/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for VGG: 1m 17s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "instances = preprocess.add_vgg_output(instances, anchor_only=True)\n",
    "end_time = time.time()\n",
    "elapsed_mins, elapsed_secs = learning_helper.epoch_time(start_time, end_time)\n",
    "print(f\"Time spent for VGG: {elapsed_mins}m {elapsed_secs}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instances, dev_instances, test_instances = preprocess.split_instances(instances)\n",
    "train_loader, dev_loader, test_loader = preprocess.get_data_loader(train_instances, dev_instances, test_instances, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from utils import evaluator\n",
    "from sklearn.metrics import classification_report\n",
    "from model.anchor_text_image import AnchorTextImageModel\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# define the label mapping\n",
    "label_to_idx = {'Yes': 1, 'No': 0}\n",
    "idx_to_label = {1: 'Yes', 0: 'No'}\n",
    "\n",
    "# parameter setting\n",
    "bert_feat_dim = 768\n",
    "vgg_feat_dim = 1000\n",
    "output_dim = 2\n",
    "hidden_dim = 4096\n",
    "dropout_rate = 0.2\n",
    "learning_rate = 1e-03\n",
    "    \n",
    "# get the model based on mode and move model to GPU is GPU is available\n",
    "classifier = AnchorTextImageModel()\n",
    "classifier = classifier.to(device)\n",
    "\n",
    "# define the optimizer, loos function, and some parameters\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Epoch: 1 || Epoch Time: 0m 3s\n",
      "Epoch: 1 || Train loss: 0.10, Train Acc: 0.62\n",
      "Epoch: 1 || Dev loss: 0.04, Dev Acc: 0.67\n",
      "------------------------------------------------------------\n",
      "Epoch: 2 || Epoch Time: 0m 3s\n",
      "Epoch: 2 || Train loss: 0.04, Train Acc: 0.67\n",
      "Epoch: 2 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "------------------------------------------------------------\n",
      "Epoch: 3 || Epoch Time: 0m 3s\n",
      "Epoch: 3 || Train loss: 0.04, Train Acc: 0.66\n",
      "Epoch: 3 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 4 || Epoch Time: 0m 3s\n",
      "Epoch: 4 || Train loss: 0.04, Train Acc: 0.68\n",
      "Epoch: 4 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 5 || Epoch Time: 0m 3s\n",
      "Epoch: 5 || Train loss: 0.04, Train Acc: 0.68\n",
      "Epoch: 5 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 6 || Epoch Time: 0m 3s\n",
      "Epoch: 6 || Train loss: 0.04, Train Acc: 0.67\n",
      "Epoch: 6 || Dev loss: 0.05, Dev Acc: 0.35\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 7 || Epoch Time: 0m 3s\n",
      "Epoch: 7 || Train loss: 0.04, Train Acc: 0.67\n",
      "Epoch: 7 || Dev loss: 0.05, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 8 || Epoch Time: 0m 3s\n",
      "Epoch: 8 || Train loss: 0.04, Train Acc: 0.67\n",
      "Epoch: 8 || Dev loss: 0.04, Dev Acc: 0.67\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 9 || Epoch Time: 0m 3s\n",
      "Epoch: 9 || Train loss: 0.04, Train Acc: 0.67\n",
      "Epoch: 9 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 10 || Epoch Time: 0m 3s\n",
      "Epoch: 10 || Train loss: 0.04, Train Acc: 0.68\n",
      "Epoch: 10 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 11 || Epoch Time: 0m 3s\n",
      "Epoch: 11 || Train loss: 0.04, Train Acc: 0.68\n",
      "Epoch: 11 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 12 || Epoch Time: 0m 3s\n",
      "Epoch: 12 || Train loss: 0.04, Train Acc: 0.68\n",
      "Epoch: 12 || Dev loss: 0.04, Dev Acc: 0.67\n",
      "The loss on development set does not decrease\n",
      "The loss on development set does not decrease, stop training!\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00       226\n",
      "         Yes       0.68      1.00      0.81       473\n",
      "\n",
      "    accuracy                           0.68       699\n",
      "   macro avg       0.34      0.50      0.40       699\n",
      "weighted avg       0.46      0.68      0.55       699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "patience = 10\n",
    "best_valid_loss = float('inf')\n",
    "check_stopping = 0\n",
    "model_name = f'retrained_{mode}_classifier.pkl'\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc = learning_helper.train(classifier, train_loader, optimizer, criterion, device, label_to_idx)\n",
    "    dev_loss, dev_acc = learning_helper.evaluate(classifier, dev_loader, criterion, device, label_to_idx)\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_mins, elapsed_secs = learning_helper.epoch_time(start_time, end_time)\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Epoch: {i+1} || Epoch Time: {elapsed_mins}m {elapsed_secs}s\")\n",
    "    print(f\"Epoch: {i+1} || Train loss: {train_loss:.02f}, Train Acc: {train_acc:.02f}\")\n",
    "    print(f\"Epoch: {i+1} || Dev loss: {dev_loss:.02f}, Dev Acc: {dev_acc:.02f}\")\n",
    "\n",
    "    # check if we need to save the model\n",
    "    if dev_loss < best_valid_loss:\n",
    "        check_stopping = 0\n",
    "        best_valid_loss = dev_loss\n",
    "        torch.save(classifier, model_name)\n",
    "    else:\n",
    "        check_stopping += 1\n",
    "        print(f\"The loss on development set does not decrease\")\n",
    "        if check_stopping == patience:\n",
    "            print(\"The loss on development set does not decrease, stop training!\")\n",
    "            break\n",
    "            \n",
    "classifier.eval()\n",
    "pred_labels = evaluator.test_model(classifier, test_loader, idx_to_label, device)\n",
    "gold_labels = [x['adjudicated_label'] for x in test_instances]\n",
    "print('-' * 60)\n",
    "print(classification_report(gold_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## complicaed_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from utils import preprocess\n",
    "from utils import learning_helper\n",
    "\n",
    "data_dir = 'data/annotations/new_annot.json'\n",
    "mode = 'all_bert_only'\n",
    "\n",
    "instances = preprocess.load_data(data_dir, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3494/3494 [04:19<00:00, 13.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for BERT: 4m 44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "instances = preprocess.add_bert_output(instances, anchor_only=False)\n",
    "end_time = time.time()\n",
    "elapsed_mins, elapsed_secs = learning_helper.epoch_time(start_time, end_time)\n",
    "print(f\"Time spent for BERT: {elapsed_mins}m {elapsed_secs}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting additional features using SpaCy ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3494/3494 [02:33<00:00, 22.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for SpaCy preprocessing: 2m 34s\n"
     ]
    }
   ],
   "source": [
    "# load MPQA lexicon\n",
    "mpqa_path = os.path.join('data', 'reference', 'MPQA_Lexicon')\n",
    "mpqa_lexicon = preprocess.load_mpqa(mpqa_path)\n",
    "\n",
    "# extract additional features\n",
    "print(\"Extracting additional features using SpaCy ...\")\n",
    "start_time = time.time()\n",
    "instances = preprocess.add_additional_features(instances, mpqa_lexicon)\n",
    "end_time = time.time()\n",
    "elapsed_mins, elapsed_secs = learning_helper.epoch_time(start_time, end_time)\n",
    "print(f\"Time spent for SpaCy preprocessing: {elapsed_mins}m {elapsed_secs}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instances, dev_instances, test_instances = preprocess.split_instances(instances)\n",
    "train_loader, dev_loader, test_loader = preprocess.get_data_loader(train_instances, dev_instances, test_instances, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 16058])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_loader:\n",
    "    print(x.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1526"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_instances[0]['anchor_addfeattensor'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78877765d71c454a8709cd8e24b4d1ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-537677b28974>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0mtemp_instances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m \u001b[0mnew_instances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_additional_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_instances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-537677b28974>\u001b[0m in \u001b[0;36madd_additional_features\u001b[0;34m(instances)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en_core_web_sm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'emoji'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mcontextualSpellCheck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mfeat_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#     pbar = tqdm(total=len(instances))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/torch/lib/python3.8/site-packages/contextualSpellCheck/__init__.py\u001b[0m in \u001b[0;36madd_to_pipe\u001b[0;34m(nlp, **kwargs)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0madd_to_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"contextual spellchecker\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/envs/torch/lib/python3.8/site-packages/spacy/language.py\u001b[0m in \u001b[0;36madd_pipe\u001b[0;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[1;32m    771\u001b[0m                     \u001b[0mlang_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m                 )\n\u001b[0;32m--> 773\u001b[0;31m             pipe_component = self.create_pipe(\n\u001b[0m\u001b[1;32m    774\u001b[0m                 \u001b[0mfactory_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/torch/lib/python3.8/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mcreate_pipe\u001b[0;34m(self, factory_name, name, config, raw_config, validate)\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# We're calling the internal _fill here to avoid constructing the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0;31m# registered functions twice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m         \u001b[0mresolved\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m         \u001b[0mfilled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"cfg\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfactory_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cfg\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0mfilled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/torch/lib/python3.8/site-packages/thinc/config.py\u001b[0m in \u001b[0;36mresolve\u001b[0;34m(cls, config, schema, overrides, validate)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m     ) -> Dict[str, Any]:\n\u001b[0;32m--> 727\u001b[0;31m         resolved, _ = cls._make(\n\u001b[0m\u001b[1;32m    728\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresolve\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m         )\n",
      "\u001b[0;32m~/envs/torch/lib/python3.8/site-packages/thinc/config.py\u001b[0m in \u001b[0;36m_make\u001b[0;34m(cls, config, schema, overrides, resolve, validate)\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_interpolated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m         filled, _, resolved = cls._fill(\n\u001b[0m\u001b[1;32m    777\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresolve\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         )\n",
      "\u001b[0;32m~/envs/torch/lib/python3.8/site-packages/thinc/config.py\u001b[0m in \u001b[0;36m_fill\u001b[0;34m(cls, config, schema, validate, resolve, parent, overrides)\u001b[0m\n\u001b[1;32m    846\u001b[0m                     \u001b[0;31m# We don't want to try/except this and raise our own error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m                     \u001b[0;31m# here, because we want the traceback if the function fails.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m                     \u001b[0mgetter_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m                     \u001b[0;31m# We're not resolving and calling the function, so replace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/torch/lib/python3.8/site-packages/contextualSpellCheck/contextualSpellCheck.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, nlp, name, vocab_path, model_name, max_edit_dist, debug, performance)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transformers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetLevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBertModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForMaskedLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/torch/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             return cls._model_mapping[type(config)].from_pretrained(\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             )\n",
      "\u001b[0;32m~/envs/torch/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m                 \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m                 resolved_archive_file = cached_path(\n\u001b[0m\u001b[1;32m   1031\u001b[0m                     \u001b[0marchive_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m                     \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/torch/lib/python3.8/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1163\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_remote_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;31m# URL, so get it from the cache (downloading if necessary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m         output_path = get_from_cache(\n\u001b[0m\u001b[1;32m   1166\u001b[0m             \u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/torch/lib/python3.8/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1426\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{url} not found in cache or force_download set to True, downloading to {temp_file.name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1428\u001b[0;31m             \u001b[0mhttp_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_to_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"storing {url} in cache at {cache_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/torch/lib/python3.8/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers)\u001b[0m\n\u001b[1;32m   1285\u001b[0m         \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_verbosity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOTSET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m     )\n\u001b[0;32m-> 1287\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# filter out keep-alive new chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m             \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/torch/lib/python3.8/site-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stream'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/torch/lib/python3.8/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/torch/lib/python3.8/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfp_closed\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m                 if (\n\u001b[1;32m    520\u001b[0m                     \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import spacy\n",
    "import os\n",
    "import torch\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def add_additional_features(instances):\n",
    "    mpqa_path = os.path.join('data', 'reference', 'MPQA_Lexicon')\n",
    "    mpqa_lexicon = preprocess.load_mpqa(mpqa_path)\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    nlp.add_pipe('emoji', first=True)\n",
    "    feat_dicts = []\n",
    "#     pbar = tqdm(total=len(instances))\n",
    "    for instance in instances:\n",
    "        # ensure the order is the same as in the later part\n",
    "        keys = sorted([key for key in instance.keys() if key.endswith(\"tweettext\")])\n",
    "        for key in keys:\n",
    "                \n",
    "            tweet = nlp(instance[key])\n",
    "            print('-' * 60)\n",
    "            print(tweet)\n",
    "            print(tweet._.performed_spellCheck)\n",
    "            featkey = key.split(\"_\")[0] + \"_addfeat\"\n",
    "            addfeat = {}\n",
    "\n",
    "            # entirely uppercase words\n",
    "            num_uppercasewords = len(['x' for token in tweet if token.text.isupper()])\n",
    "            addfeat['num_uppercasewords'] = num_uppercasewords\n",
    "\n",
    "            # the number of URLs\n",
    "            num_urls = len(['x' for token in tweet if token.text.startswith(\"http\")])\n",
    "            addfeat['num_urls'] = num_urls\n",
    "\n",
    "            # the number of exclamation marks\n",
    "            num_exclamationmarks = len(['x' for token in tweet if token.text == '!'])\n",
    "            addfeat['num_exclamationmarks'] = num_exclamationmarks\n",
    "\n",
    "            # the number of strongly subjective words in MPQA lexicon\n",
    "            num_strongsubj = len([token for token in tweet if token.text in mpqa_lexicon['strongsubj']])\n",
    "            addfeat['num_strongsubj'] = num_strongsubj\n",
    "\n",
    "            # the number of weakly subjective words in MPQA lexicon\n",
    "            num_weaksubj = len([token for token in tweet if token.text in mpqa_lexicon['weaksubj']])\n",
    "            addfeat['num_weaksubj'] = num_weaksubj\n",
    "\n",
    "            # the number of emoji\n",
    "            num_emoji = len(tweet._.emoji)\n",
    "            addfeat['num_emoji'] = num_emoji\n",
    "            \n",
    "            # the three most common emoji (in the form of description)\n",
    "            emoji_desc_lists = [token._.emoji_desc for token in tweet if token._.is_emoji]\n",
    "            emoji_count = Counter(emoji_desc_lists).most_common(3)\n",
    "            for index, x in enumerate(emoji_count):\n",
    "                addfeat[f\"no.{index+1}_emoji\"] = x[0]\n",
    "                \n",
    "            # the number of tokens\n",
    "            num_tokens = len(tweet)\n",
    "            addfeat['num_tokens'] = num_tokens\n",
    "            \n",
    "            # spellcheck\n",
    "            \n",
    "            \n",
    "            instance[featkey] = addfeat\n",
    "            feat_dicts.append(addfeat)\n",
    "            \n",
    "            break\n",
    "        break\n",
    "#         pbar.update(1)\n",
    "#     pbar.close()\n",
    "    \n",
    "#     dv = DictVectorizer(sparse=False)\n",
    "#     feat_vectorized = dv.fit_transform(feat_dicts)\n",
    "    \n",
    "#     for index_outside, instance in enumerate(instances):\n",
    "#         small_feats = feat_vectorized[index_outside*7:(index_outside+1)*7]\n",
    "#         # ensure the order is the same as the previous part\n",
    "#         keys = sorted([key for key in instance.keys() if key.endswith(\"tweettext\")])\n",
    "#         for index_inside, key in enumerate(keys):\n",
    "#             newfeatkey = key.split(\"_\")[0] + \"_addfeattensor\"\n",
    "#             feattensor = torch.FloatTensor(small_feats[index_inside]).unsqueeze(0).to('cpu')\n",
    "#             instance[newfeatkey] = feattensor\n",
    "            \n",
    "    return instances, feat_dicts\n",
    "\n",
    "temp_instances = instances.copy()\n",
    "new_instances, feat_dicts = add_additional_features(temp_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1519])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def temp(instances, feat_dicts):\n",
    "    dv = DictVectorizer(sparse=False, dtype=int)\n",
    "    feat_vectorized = dv.fit_transform(feat_dicts)\n",
    "\n",
    "    for index_outside, instance in enumerate(instances):\n",
    "        small_feats = feat_vectorized[index_outside*7:(index_outside+1)*7]\n",
    "        # ensure the order is the same as the previous part\n",
    "        keys = sorted([key for key in instance.keys() if key.endswith(\"tweettext\")])\n",
    "        for index_inside, key in enumerate(keys):\n",
    "            newfeatkey = key.split(\"_\")[0] + \"_addfeattensor\"\n",
    "            feattensor = torch.FloatTensor(small_feats[index_inside]).unsqueeze(0).to('cpu')\n",
    "            instance[newfeatkey] = feattensor\n",
    "    return instances\n",
    "\n",
    "aa_ins = temp(new_instances, feat_dicts)\n",
    "aa_ins[0]['anchor_addfeattensor'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# parameter setting\n",
    "bert_feat_dim = 768\n",
    "output_dim = 2\n",
    "hidden_dim = 2048\n",
    "dropout_rate = 0.5\n",
    "\n",
    "\n",
    "class Test(nn.Module):\n",
    "\n",
    "    def __init__(self, additional_feat_dim=0):\n",
    "        super(Test, self).__init__()\n",
    "        self.bert_feat_dim = bert_feat_dim\n",
    "        self.additional_feat_dim = additional_feat_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "#         self.fc1 = nn.Linear(self.bert_feat_dim*7, hidden_dim)\n",
    "        self.fc1 = nn.Linear((self.bert_feat_dim+self.additional_feat_dim)*7, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, feat_combined):\n",
    "\n",
    "#         # split the combined feature\n",
    "#         bert_feat = feat_combined[:, :self.bert_feat_dim * 7]\n",
    "#         additional_feat = feat_combined[:, self.bert_feat_dim * 7:]\n",
    "\n",
    "        # pass fully-connected layer\n",
    "        out = self.fc1(feat_combined)\n",
    "        out = F.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instances, dev_instances, test_instances = preprocess.split_instances(instances)\n",
    "train_loader, dev_loader, test_loader = preprocess.get_data_loader(train_instances, dev_instances, test_instances, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# parameter setting\n",
    "bert_feat_dim = 768\n",
    "lstm_dim = 512\n",
    "output_dim = 2\n",
    "hidden_dim = 512\n",
    "dropout_rate = 0.5\n",
    "\n",
    "\n",
    "class Test(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Test, self).__init__()\n",
    "        self.bert_feat_dim = bert_feat_dim\n",
    "        self.lstm_dim = lstm_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.lstm = nn.LSTM(self.bert_feat_dim, self.lstm_dim, batch_first=True, bidirectional=True)\n",
    "#         self.fc_combined = nn.Linear(self.bert_feat_dim*7+self.lstm_dim*2, hidden_dim)\n",
    "#         self.fc1 = nn.Linear(self.lstm_dim*2, hidden_dim)\n",
    "#         self.fc1 = nn.Linear(self.lstm_dim*2+self.bert_feat_dim, hidden_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim*3, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        # test\n",
    "        self.fc_lstm = nn.Linear(self.lstm_dim*2, self.hidden_dim)\n",
    "        self.fc_combined = nn.Linear(self.lstm_dim*2+self.bert_feat_dim, self.hidden_dim)\n",
    "        self.fc_anchor = nn.Linear(self.bert_feat_dim, self.hidden_dim)        \n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.bn = nn.BatchNorm1d(self.lstm_dim*2, affine=True)\n",
    "\n",
    "    def forward(self, feat_combined):\n",
    "        \n",
    "        # get the bert output\n",
    "        context1_feat = feat_combined[:, :self.bert_feat_dim * 1].unsqueeze(1)\n",
    "        context2_feat = feat_combined[:, self.bert_feat_dim * 1:self.bert_feat_dim * 2].unsqueeze(1)\n",
    "        context3_feat = feat_combined[:, self.bert_feat_dim * 2:self.bert_feat_dim * 3].unsqueeze(1)\n",
    "        anchor_feat = feat_combined[:, self.bert_feat_dim * 3:self.bert_feat_dim * 4].unsqueeze(1)\n",
    "        context4_feat = feat_combined[:, self.bert_feat_dim * 4:self.bert_feat_dim * 5].unsqueeze(1)\n",
    "        context5_feat = feat_combined[:, self.bert_feat_dim * 5:self.bert_feat_dim * 6].unsqueeze(1)\n",
    "        context6_feat = feat_combined[:, self.bert_feat_dim * 6:self.bert_feat_dim * 7].unsqueeze(1)\n",
    "\n",
    "        # get the additional features\n",
    "        addfeat_dim = int((feat_combined.shape[0] - self.bert_feat_dim * 7) / 7)\n",
    "        context1_addfeat = feat_combined[:, self.bert_feat_dim * 7 + addfeat_dim * 0:self.bert_feat_dim * 7 + addfeat_dim * 1].unsqueeze(1)\n",
    "        context2_addfeat = feat_combined[:, self.bert_feat_dim * 7 + addfeat_dim * 1:self.bert_feat_dim * 7 + addfeat_dim * 2].unsqueeze(1)\n",
    "        context3_addfeat = feat_combined[:, self.bert_feat_dim * 7 + addfeat_dim * 2:self.bert_feat_dim * 7 + addfeat_dim * 3].unsqueeze(1)\n",
    "        anchor_addfeat = feat_combined[:, self.bert_feat_dim * 7 + addfeat_dim * 3:self.bert_feat_dim * 7 + addfeat_dim * 4].unsqueeze(1)\n",
    "        context4_addfeat = feat_combined[:, self.bert_feat_dim * 7 + addfeat_dim * 4:self.bert_feat_dim * 7 + addfeat_dim * 5].unsqueeze(1)\n",
    "        context5_addfeat = feat_combined[:, self.bert_feat_dim * 7 + addfeat_dim * 5:self.bert_feat_dim * 7 + addfeat_dim * 6].unsqueeze(1)\n",
    "        context6_addfeat = feat_combined[:, self.bert_feat_dim * 7 + addfeat_dim * 6:self.bert_feat_dim * 7 + addfeat_dim * 7].unsqueeze(1)\n",
    "\n",
    "        # prepare for the input of LSTM\n",
    "        lstm_input = torch.cat((\n",
    "            context1_feat,\n",
    "            context2_feat,\n",
    "            context3_feat,\n",
    "#             anchor_feat,\n",
    "            context4_feat,\n",
    "            context5_feat,\n",
    "            context6_feat\n",
    "        ), dim=1)\n",
    "        \n",
    "        # pass the LSTM\n",
    "        lstm_output, _ = self.lstm(lstm_input)\n",
    "        \n",
    "        # only take the last hidden state\n",
    "#         out = out[:, -1, :]\n",
    "\n",
    "        # global maxpooling on the BiLSTM output\n",
    "        lstm_output = nn.AvgPool1d(6, 6)(lstm_output.permute(0,2,1)).permute(0,2,1).squeeze(1)\n",
    "        \n",
    "        combined_out = torch.cat((lstm_output, anchor_feat.squeeze(1)), dim=1)\n",
    "        \n",
    "        lstm_output = self.fc_lstm(lstm_output)\n",
    "        combined_out = self.fc_combined(combined_out)\n",
    "        anchor_feat = self.fc_anchor(anchor_feat).squeeze(1)\n",
    "        \n",
    "        all_combined = torch.cat((lstm_output, combined_out, anchor_feat), dim=1)\n",
    "        \n",
    "#         print(out.shape)\n",
    "        \n",
    "        # batch normalization\n",
    "#         out = self.bn(out)\n",
    "        \n",
    "        # pass the fully-connected layer(s)\n",
    "        out = self.fc1(all_combined)\n",
    "        out = F.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "# define the label mapping\n",
    "label_to_idx = {'Yes': 1, 'No': 0}\n",
    "idx_to_label = {1: 'Yes', 0: 'No'}\n",
    "    \n",
    "# define some global parameters\n",
    "num_epochs = 1000\n",
    "batch_size = 16\n",
    "patience = 10\n",
    "learning_rate = 1e-04\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "additional_feat_dim = train_instances[0]['anchor_addfeattensor'].shape[1]\n",
    "classifier = Test(additional_feat_dim=additional_feat_dim)\n",
    "classifier = classifier.to(device)\n",
    "\n",
    "# define the optimizer, loos function, and some parameters\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Epoch: 1 || Epoch Time: 0m 1s\n",
      "Epoch: 1 || Train loss: 0.04, Train Acc: 0.65\n",
      "Epoch: 1 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "------------------------------------------------------------\n",
      "Epoch: 2 || Epoch Time: 0m 1s\n",
      "Epoch: 2 || Train loss: 0.04, Train Acc: 0.66\n",
      "Epoch: 2 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "------------------------------------------------------------\n",
      "Epoch: 3 || Epoch Time: 0m 1s\n",
      "Epoch: 3 || Train loss: 0.04, Train Acc: 0.68\n",
      "Epoch: 3 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 4 || Epoch Time: 0m 1s\n",
      "Epoch: 4 || Train loss: 0.04, Train Acc: 0.69\n",
      "Epoch: 4 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 5 || Epoch Time: 0m 1s\n",
      "Epoch: 5 || Train loss: 0.04, Train Acc: 0.69\n",
      "Epoch: 5 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 6 || Epoch Time: 0m 1s\n",
      "Epoch: 6 || Train loss: 0.04, Train Acc: 0.71\n",
      "Epoch: 6 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 7 || Epoch Time: 0m 2s\n",
      "Epoch: 7 || Train loss: 0.03, Train Acc: 0.72\n",
      "Epoch: 7 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 8 || Epoch Time: 0m 1s\n",
      "Epoch: 8 || Train loss: 0.03, Train Acc: 0.74\n",
      "Epoch: 8 || Dev loss: 0.05, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 9 || Epoch Time: 0m 1s\n",
      "Epoch: 9 || Train loss: 0.03, Train Acc: 0.75\n",
      "Epoch: 9 || Dev loss: 0.05, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 10 || Epoch Time: 0m 2s\n",
      "Epoch: 10 || Train loss: 0.03, Train Acc: 0.75\n",
      "Epoch: 10 || Dev loss: 0.05, Dev Acc: 0.67\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 11 || Epoch Time: 0m 1s\n",
      "Epoch: 11 || Train loss: 0.03, Train Acc: 0.77\n",
      "Epoch: 11 || Dev loss: 0.05, Dev Acc: 0.67\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 12 || Epoch Time: 0m 1s\n",
      "Epoch: 12 || Train loss: 0.03, Train Acc: 0.78\n",
      "Epoch: 12 || Dev loss: 0.05, Dev Acc: 0.67\n",
      "The loss on development set does not decrease\n",
      "The loss on development set does not decrease, stop training!\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.50      0.03      0.06       226\n",
      "         Yes       0.68      0.99      0.80       473\n",
      "\n",
      "    accuracy                           0.68       699\n",
      "   macro avg       0.59      0.51      0.43       699\n",
      "weighted avg       0.62      0.68      0.56       699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import evaluator\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "num_epochs = 500\n",
    "patience = 10\n",
    "best_valid_loss = float('inf')\n",
    "check_stopping = 0\n",
    "model_name = f'retrained_{mode}_classifier.pt'\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    start_time = time.time()\n",
    "    classifier.train()\n",
    "    train_loss, train_acc = learning_helper.train(classifier, train_loader, optimizer, criterion, device, label_to_idx)\n",
    "    dev_loss, dev_acc = learning_helper.evaluate(classifier, dev_loader, criterion, device, label_to_idx)\n",
    "    classifier.train()\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_mins, elapsed_secs = learning_helper.epoch_time(start_time, end_time)\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Epoch: {i+1} || Epoch Time: {elapsed_mins}m {elapsed_secs}s\")\n",
    "    print(f\"Epoch: {i+1} || Train loss: {train_loss:.02f}, Train Acc: {train_acc:.02f}\")\n",
    "    print(f\"Epoch: {i+1} || Dev loss: {dev_loss:.02f}, Dev Acc: {dev_acc:.02f}\")\n",
    "\n",
    "    # check if we need to save the model\n",
    "    if dev_loss < best_valid_loss:\n",
    "        check_stopping = 0\n",
    "        best_valid_loss = dev_loss\n",
    "        torch.save(classifier.state_dict(), model_name)\n",
    "    else:\n",
    "        check_stopping += 1\n",
    "        print(f\"The loss on development set does not decrease\")\n",
    "        if check_stopping == patience:\n",
    "            print(\"The loss on development set does not decrease, stop training!\")\n",
    "            break\n",
    "            \n",
    "classifier.eval()\n",
    "pred_labels = evaluator.test_model(classifier, test_loader, idx_to_label, device)\n",
    "gold_labels = [x['adjudicated_label'] for x in test_instances]\n",
    "print('-' * 60)\n",
    "print(classification_report(gold_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.31      0.06      0.10       226\n",
      "         Yes       0.68      0.94      0.79       473\n",
      "\n",
      "    accuracy                           0.65       699\n",
      "   macro avg       0.49      0.50      0.44       699\n",
      "weighted avg       0.56      0.65      0.56       699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load pretrained model\n",
    "classifier = Test()\n",
    "classifier = classifier.to(device)\n",
    "classifier.load_state_dict(torch.load(model_name))\n",
    "pred_labels = evaluator.test_model(classifier, test_loader, idx_to_label, device)\n",
    "gold_labels = [x['adjudicated_label'] for x in test_instances]\n",
    "print('-' * 60)\n",
    "print(classification_report(gold_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add more info to the annotation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "annotation_filepath = 'data/annotations/annotation_context.json'\n",
    "original_batch_filepath = 'batch_6540.csv'\n",
    "data_dir = 'data'\n",
    "\n",
    "lookup_dict = defaultdict(dict)\n",
    "with open(original_batch_filepath, 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        lookup_dict[row['instance_id']] = row\n",
    "        \n",
    "def add_info(lookup_dict, annotation_filepath):\n",
    "    instances = []\n",
    "    with open(annotation_filepath, 'r') as jsonfile:\n",
    "        lines = jsonfile.read().split(\"\\n\")[:-1]\n",
    "        for line in lines:\n",
    "            instance = {}\n",
    "            temp_instance = json.loads(line)\n",
    "            # remove \"Input.\" in the keys\n",
    "            for key, value in temp_instance.items():\n",
    "                if key.startswith(\"Input.\"):\n",
    "                    if not key.endswith(\"url\"):\n",
    "                        newkey = key.split(\".\")[-1]\n",
    "                        instance[newkey] = value\n",
    "                else:\n",
    "                    instance[key] = value\n",
    "\n",
    "            # add image filepath, json filepath, screenshot url, tweet_text, and timestamp\n",
    "            original_dict = lookup_dict[temp_instance['Input.instance_id']]\n",
    "            for key, value in original_dict.items():\n",
    "                if key.endswith(\"url\"):\n",
    "                    tweet_id = value.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0]\n",
    "\n",
    "                    # add json filepath\n",
    "                    jsonname = f\"anchor_{tweet_id}.json\" if 'anchor' in key else f\"{tweet_id}.json\"\n",
    "                    jsonpath = os.path.join(data_dir, 'json_files', '_'.join(value.split(\"/\")[-1].split(\"_\")[:2]), jsonname)\n",
    "                    jsonkey = key.split(\"_\")[0] + \"_jsonpath\"\n",
    "                    instance[jsonkey] = jsonpath\n",
    "\n",
    "                    # add tweet text\n",
    "                    with open(jsonpath, 'r') as tweetfile:\n",
    "                        tweet = json.loads(tweetfile.read())\n",
    "                    textkey = key.split(\"_\")[0] + \"_tweettext\"\n",
    "                    instance[textkey] = tweet['full_text']\n",
    "\n",
    "                    # add image filepath if image exists\n",
    "                    instance[key] = value\n",
    "                    imagename = f\"anchor_{tweet_id}.jpg\" if 'anchor' in key else f\"{tweet_id}.jpg\"\n",
    "                    imagepath = os.path.join(data_dir, 'image_files', '_'.join(value.split(\"/\")[-1].split(\"_\")[:2]), imagename)\n",
    "                    hasimg = os.path.isfile(imagepath)\n",
    "                    if hasimg:\n",
    "                        imagekey = key.split(\"_\")[0] + \"_imagepath\"\n",
    "                        instance[imagekey] = imagepath\n",
    "\n",
    "                if key.endswith(\"timestamp\"):\n",
    "                    instance[key] = original_dict[key]\n",
    "            instances.append(instance)\n",
    "    return instances\n",
    "\n",
    "instances = add_info(lookup_dict, annotation_filepath)\n",
    "\n",
    "new_annot_filename = 'new_annot.json'\n",
    "with open(new_annot_filename, 'w') as newjson:\n",
    "    for instance in instances:\n",
    "        newjson.write(json.dumps(instance))\n",
    "        newjson.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## copy the json file and image file to the loctmp2 folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import os\n",
    "from shutil import copyfile\n",
    "\n",
    "original_folder = '/media/zhaomin/Zhaomin_SSD/project_repo/emnlp2021/saved_tweets_original'\n",
    "data_dir = 'data'\n",
    "\n",
    "original_batch_filepath = 'batch_6540.csv'\n",
    "lookup_dict = defaultdict(dict)\n",
    "with open(original_batch_filepath, 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        lookup_dict[row['instance_id']] = row\n",
    "        \n",
    "annotation_filepath = 'data/annotations/annotation_context.json'\n",
    "with open(annotation_filepath, 'r') as jsonfile:\n",
    "    lines = jsonfile.read().split(\"\\n\")[:-1]\n",
    "    for line in lines:\n",
    "        instance = json.loads(line)\n",
    "        instance_id = instance['Input.instance_id']\n",
    "        \n",
    "        # create folder if it does not exist\n",
    "        if not os.path.isdir(os.path.join(data_dir, 'json_files', instance_id)):\n",
    "            os.mkdir(os.path.join(data_dir, 'json_files', instance_id))\n",
    "        if not os.path.isdir(os.path.join(data_dir, 'image_files', instance_id)):\n",
    "            os.mkdir(os.path.join(data_dir, 'image_files', instance_id))\n",
    "            \n",
    "        # find event path\n",
    "        original_dict = lookup_dict[instance_id]\n",
    "        event_name = re.split('(\\d+)', instance_id.split(\"_\")[0])[0]\n",
    "        for original_event in os.listdir(original_folder):\n",
    "            \n",
    "            # make sure the event and year are matched\n",
    "            if original_event.split(\"_\")[0] == event_name:\n",
    "                if original_event.split(\"_\")[1].split(\"-\")[0] == re.split('(\\d+)', instance_id.split(\"_\")[0])[1]:\n",
    "                    original_event_path = os.path.join(original_folder, original_event, f\"final_tweet_folder_{original_event}\", instance_id.split(\"_\")[-1])\n",
    "                    break\n",
    "        \n",
    "        for key, value in original_dict.items():\n",
    "            if key.endswith(\"url\"):\n",
    "                \n",
    "                if 'anchor' in key:\n",
    "                    real_instance_id = value.split(\"/\")[-1].split(\"_\")[1]\n",
    "                    src_jsonfilename = f\"anchor_{real_instance_id}.json\"\n",
    "                    src_imagefilename = f\"anchor_{real_instance_id}.jpg\"\n",
    "                    src_jsonfilepath = os.path.join(original_event_path, src_jsonfilename)\n",
    "                    src_imagefilepath = os.path.join(original_event_path, src_imagefilename)\n",
    "                    dst_jsonfilepath = os.path.join(data_dir, 'json_files', instance_id, src_jsonfilename)\n",
    "                    dst_imagefilepath = os.path.join(data_dir, 'image_files', instance_id, src_imagefilename)\n",
    "                    copyfile(src_jsonfilepath, dst_jsonfilepath)\n",
    "                    copyfile(src_imagefilepath, dst_imagefilepath)\n",
    "                \n",
    "                else:\n",
    "                    tweet_id = value.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1]\n",
    "                    \n",
    "                    # copy json file\n",
    "                    src_jsonfilename = f\"{tweet_id}.json\"\n",
    "                    src_jsonfilepath = os.path.join(original_event_path, src_jsonfilename)\n",
    "                    dst_jsonfilepath = os.path.join(data_dir, 'json_files', instance_id, src_jsonfilename)\n",
    "                    copyfile(src_jsonfilepath, dst_jsonfilepath)\n",
    "                    \n",
    "                    # copy image file if it exists\n",
    "                    src_imagefilename = f\"{tweet_id}.jpg\"\n",
    "                    if src_imagefilename in os.listdir(original_event_path):\n",
    "                        src_imagefilepath = os.path.join(original_event_path, src_imagefilename)\n",
    "                        dst_imagefilepath = os.path.join(data_dir, 'image_files', instance_id, src_imagefilename)\n",
    "                        copyfile(src_imagefilepath, dst_imagefilepath)\n",
    "                    \n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save split for replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = instances\n",
    "y = [x['adjudicated_label'] for x in instances]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y)\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, test_size=0.20, stratify=y_train)\n",
    "\n",
    "split = {'train': [x['instance_id'] for x in X_train],\n",
    "         'dev': [x['instance_id'] for x in X_dev],\n",
    "         'test': [x['instance_id'] for x in X_test]}\n",
    "\n",
    "with open(\"saved_split\", 'w') as splitfile:\n",
    "    splitfile.write(json.dumps(split))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
