{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from utils import preprocess\n",
    "from utils import learning_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/annotations/new_annot.json'\n",
    "mode = 'anchor_text_image'\n",
    "\n",
    "instances = preprocess.load_data(data_dir, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for BERT: 0m 41s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "instances = preprocess.add_bert_output(instances, anchor_only=True)\n",
    "end_time = time.time()\n",
    "elapsed_mins, elapsed_secs = learning_helper.epoch_time(start_time, end_time)\n",
    "print(f\"Time spent for BERT: {elapsed_mins}m {elapsed_secs}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhaomin/envs/torch/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for VGG: 1m 17s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "instances = preprocess.add_vgg_output(instances, anchor_only=True)\n",
    "end_time = time.time()\n",
    "elapsed_mins, elapsed_secs = learning_helper.epoch_time(start_time, end_time)\n",
    "print(f\"Time spent for VGG: {elapsed_mins}m {elapsed_secs}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instances, dev_instances, test_instances = preprocess.split_instances(instances)\n",
    "train_loader, dev_loader, test_loader = preprocess.get_data_loader(train_instances, dev_instances, test_instances, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from utils import evaluator\n",
    "from sklearn.metrics import classification_report\n",
    "from model.anchor_text_image import AnchorTextImageModel\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# define the label mapping\n",
    "label_to_idx = {'Yes': 1, 'No': 0}\n",
    "idx_to_label = {1: 'Yes', 0: 'No'}\n",
    "\n",
    "# parameter setting\n",
    "bert_feat_dim = 768\n",
    "vgg_feat_dim = 1000\n",
    "output_dim = 2\n",
    "hidden_dim = 4096\n",
    "dropout_rate = 0.2\n",
    "learning_rate = 1e-03\n",
    "    \n",
    "# get the model based on mode and move model to GPU is GPU is available\n",
    "classifier = AnchorTextImageModel()\n",
    "classifier = classifier.to(device)\n",
    "\n",
    "# define the optimizer, loos function, and some parameters\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Epoch: 1 || Epoch Time: 0m 3s\n",
      "Epoch: 1 || Train loss: 0.10, Train Acc: 0.62\n",
      "Epoch: 1 || Dev loss: 0.04, Dev Acc: 0.67\n",
      "------------------------------------------------------------\n",
      "Epoch: 2 || Epoch Time: 0m 3s\n",
      "Epoch: 2 || Train loss: 0.04, Train Acc: 0.67\n",
      "Epoch: 2 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "------------------------------------------------------------\n",
      "Epoch: 3 || Epoch Time: 0m 3s\n",
      "Epoch: 3 || Train loss: 0.04, Train Acc: 0.66\n",
      "Epoch: 3 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 4 || Epoch Time: 0m 3s\n",
      "Epoch: 4 || Train loss: 0.04, Train Acc: 0.68\n",
      "Epoch: 4 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 5 || Epoch Time: 0m 3s\n",
      "Epoch: 5 || Train loss: 0.04, Train Acc: 0.68\n",
      "Epoch: 5 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 6 || Epoch Time: 0m 3s\n",
      "Epoch: 6 || Train loss: 0.04, Train Acc: 0.67\n",
      "Epoch: 6 || Dev loss: 0.05, Dev Acc: 0.35\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 7 || Epoch Time: 0m 3s\n",
      "Epoch: 7 || Train loss: 0.04, Train Acc: 0.67\n",
      "Epoch: 7 || Dev loss: 0.05, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 8 || Epoch Time: 0m 3s\n",
      "Epoch: 8 || Train loss: 0.04, Train Acc: 0.67\n",
      "Epoch: 8 || Dev loss: 0.04, Dev Acc: 0.67\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 9 || Epoch Time: 0m 3s\n",
      "Epoch: 9 || Train loss: 0.04, Train Acc: 0.67\n",
      "Epoch: 9 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 10 || Epoch Time: 0m 3s\n",
      "Epoch: 10 || Train loss: 0.04, Train Acc: 0.68\n",
      "Epoch: 10 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 11 || Epoch Time: 0m 3s\n",
      "Epoch: 11 || Train loss: 0.04, Train Acc: 0.68\n",
      "Epoch: 11 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 12 || Epoch Time: 0m 3s\n",
      "Epoch: 12 || Train loss: 0.04, Train Acc: 0.68\n",
      "Epoch: 12 || Dev loss: 0.04, Dev Acc: 0.67\n",
      "The loss on development set does not decrease\n",
      "The loss on development set does not decrease, stop training!\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00       226\n",
      "         Yes       0.68      1.00      0.81       473\n",
      "\n",
      "    accuracy                           0.68       699\n",
      "   macro avg       0.34      0.50      0.40       699\n",
      "weighted avg       0.46      0.68      0.55       699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "patience = 10\n",
    "best_valid_loss = float('inf')\n",
    "check_stopping = 0\n",
    "model_name = f'retrained_{mode}_classifier.pkl'\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc = learning_helper.train(classifier, train_loader, optimizer, criterion, device, label_to_idx)\n",
    "    dev_loss, dev_acc = learning_helper.evaluate(classifier, dev_loader, criterion, device, label_to_idx)\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_mins, elapsed_secs = learning_helper.epoch_time(start_time, end_time)\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Epoch: {i+1} || Epoch Time: {elapsed_mins}m {elapsed_secs}s\")\n",
    "    print(f\"Epoch: {i+1} || Train loss: {train_loss:.02f}, Train Acc: {train_acc:.02f}\")\n",
    "    print(f\"Epoch: {i+1} || Dev loss: {dev_loss:.02f}, Dev Acc: {dev_acc:.02f}\")\n",
    "\n",
    "    # check if we need to save the model\n",
    "    if dev_loss < best_valid_loss:\n",
    "        check_stopping = 0\n",
    "        best_valid_loss = dev_loss\n",
    "        torch.save(classifier, model_name)\n",
    "    else:\n",
    "        check_stopping += 1\n",
    "        print(f\"The loss on development set does not decrease\")\n",
    "        if check_stopping == patience:\n",
    "            print(\"The loss on development set does not decrease, stop training!\")\n",
    "            break\n",
    "            \n",
    "classifier.eval()\n",
    "pred_labels = evaluator.test_model(classifier, test_loader, idx_to_label, device)\n",
    "gold_labels = [x['adjudicated_label'] for x in test_instances]\n",
    "print('-' * 60)\n",
    "print(classification_report(gold_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## complicated_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from utils import preprocess\n",
    "from utils import learning_helper\n",
    "\n",
    "data_dir = 'data/annotations/new_annot.json'\n",
    "mode = 'all_bert_lstm'\n",
    "\n",
    "instances = preprocess.load_data(data_dir, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 3494/3494 [04:31<00:00, 12.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for BERT: 5m 0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "instances = preprocess.add_bert_output(instances, anchor_only=False)\n",
    "end_time = time.time()\n",
    "elapsed_mins, elapsed_secs = learning_helper.epoch_time(start_time, end_time)\n",
    "print(f\"Time spent for BERT: {elapsed_mins}m {elapsed_secs}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_polished(instances):\n",
    "    \"\"\"\n",
    "    split the integer feature values into some bins and convert it into string\n",
    "    :param instances: instances with integer values\n",
    "    :return: instances with string values\n",
    "    \"\"\"\n",
    "    # get the statistics of the features whose value is integer\n",
    "    bin_size = 6\n",
    "    feat_dicts = [value for instance in instances for key, value in instance.items() if key.endswith(\"addfeat\")]\n",
    "    keys = [key for key, value in feat_dicts[0].items() if isinstance(value, int)]\n",
    "    feat_numbers = {key: [feat_dict[key] for feat_dict in feat_dicts] for key in keys}\n",
    "    cutted_dict = defaultdict(dict)\n",
    "    for key, value in feat_numbers.items():\n",
    "        stats = Counter(value)\n",
    "        # only get the most common value\n",
    "        most_common = dict(stats.most_common(int(len(stats) / bin_size) + 1))\n",
    "        for small_key in most_common.keys():\n",
    "            cutted_dict[key].update({small_key: str(small_key)})\n",
    "        cutted_dict[key].update({'other': 'other'})\n",
    "\n",
    "    # update the feature value\n",
    "    for instance in instances:\n",
    "        keys = [key for key in instance.keys() if key.endswith(\"addfeat\")]\n",
    "        for key in keys:\n",
    "            feat_values = instance[key]\n",
    "            for feat_name in list(feat_values.keys()):\n",
    "                feat_value = feat_values[feat_name]\n",
    "                if not isinstance(feat_value, int):\n",
    "                    continue\n",
    "                if feat_value in cutted_dict.keys():\n",
    "                    instance[key][feat_name] = cutted_dict[feat_name][feat_value]\n",
    "                else:\n",
    "                    instance[key][feat_name] = cutted_dict[feat_name]['other']\n",
    "\n",
    "    return instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting additional features using SpaCy ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb1198546c57428bba8a5286fdc40518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3494 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for SpaCy preprocessing: 2m 46s\n",
      "additional feature dimension: 1533\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "from spellchecker import SpellChecker\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# load MPQA lexicon\n",
    "mpqa_path = os.path.join('data', 'reference', 'MPQA_Lexicon')\n",
    "mpqa_lexicon = preprocess.load_mpqa(mpqa_path)\n",
    "\n",
    "def add_additional_features(instances, mpqa_lexicon):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    nlp.add_pipe('emoji', first=True)\n",
    "    spell = SpellChecker()\n",
    "    pbar = tqdm(total=len(instances))\n",
    "    for instance in instances:\n",
    "\n",
    "        location = instance['anchor_location']\n",
    "        keys = [key for key in instance.keys() if key.endswith(\"tweettext\")]\n",
    "        for key in keys:\n",
    "            \n",
    "            tweet = nlp(instance[key])\n",
    "            featkey = key.split(\"_\")[0] + \"_addfeat\"\n",
    "            addfeat = {}\n",
    "\n",
    "            # entirely uppercase words\n",
    "            num_entireuppercasewords = len(['x' for token in tweet if token.text.isupper()])\n",
    "            addfeat['num_entireuppercasewords'] = num_entireuppercasewords\n",
    "\n",
    "            # the number of URLs\n",
    "#             num_urls = len(['x' for token in tweet if token.text.startswith(\"http\")])\n",
    "            num_urls = len(['x' for token in tweet if token.like_url])\n",
    "            addfeat['num_urls'] = num_urls\n",
    "\n",
    "            # the number of exclamation marks\n",
    "            num_exclamationmarks = len(['x' for token in tweet if token.text == '!'])\n",
    "            addfeat['num_exclamationmarks'] = num_exclamationmarks\n",
    "\n",
    "            # the number of strongly subjective words in MPQA lexicon\n",
    "            num_strongsubj = len([token for token in tweet if token.text in mpqa_lexicon['strongsubj']])\n",
    "            addfeat['num_strongsubj'] = num_strongsubj\n",
    "\n",
    "            # the number of weakly subjective words in MPQA lexicon\n",
    "            num_weaksubj = len([token for token in tweet if token.text in mpqa_lexicon['weaksubj']])\n",
    "            addfeat['num_weaksubj'] = num_weaksubj\n",
    "\n",
    "            # the number of emoji\n",
    "            num_emoji = len(tweet._.emoji)\n",
    "            addfeat['num_emoji'] = num_emoji\n",
    "\n",
    "            # the three most common emoji (in the form of description)\n",
    "            emoji_desc_lists = [token._.emoji_desc for token in tweet if token._.is_emoji]\n",
    "            emoji_count = Counter(emoji_desc_lists).most_common(3)\n",
    "            for index, x in enumerate(emoji_count):\n",
    "                addfeat[f\"no.{index + 1}_emoji\"] = x[0]\n",
    "\n",
    "            # the number of tokens\n",
    "            num_tokens = len(tweet)\n",
    "            addfeat['num_tokens'] = num_tokens\n",
    "            \n",
    "            # the number of elongated words\n",
    "            elong_pattern = re.compile(\"([a-zA-Z])\\\\1{2,}\")\n",
    "            num_elong = len(['x' for token in tweet if bool(elong_pattern.search(token.text))])\n",
    "            addfeat['num_elong'] = num_elong\n",
    "            \n",
    "            # the number of hashtags\n",
    "            num_hashtags = len(['x' for token in tweet if token.text.startswith(\"#\")])\n",
    "            addfeat['num_hashtags'] = num_hashtags\n",
    "            \n",
    "            # the number of first letter uppercased words\n",
    "            num_uppercasewords = len(['x' for token in tweet if token.text[0].isupper()])\n",
    "            addfeat['num_uppercasewords'] = num_uppercasewords\n",
    "            \n",
    "#             # the number of misspelled words (needs to be polished)\n",
    "#             checklists = [[token.text] for token in tweet]\n",
    "#             num_misspell = sum([len(spell.unknown(checklist)) for checklist in checklists])\n",
    "#             addfeat['num_misspell'] = str(num_misspell)\n",
    "            \n",
    "            # the surround words/lemma/pos/hashtag/reply\n",
    "            contain_location = False\n",
    "            for token in tweet:\n",
    "                if location in token.text:\n",
    "                    contain_location = True\n",
    "                    \n",
    "                    # check if the location is included in a hashtag\n",
    "                    addfeat['loc_hashtag'] = '1' if token.text.startswith(\"#\") else '0'\n",
    "                    \n",
    "                    # check if the location is included in a mention\n",
    "                    addfeat['loc_mention'] = '1' if token.text.startswith(\"@\") else '0'\n",
    "                    \n",
    "#                     # previous word\n",
    "#                     previous_word = tweet[token.i-1].text if token.i > 0 else 'nan'\n",
    "#                     addfeat['previous_word'] = previous_word\n",
    "                    \n",
    "                    break\n",
    "            if not contain_location:\n",
    "                addfeat['loc_hashtag'] = '0'\n",
    "                addfeat['loc_mention'] = '0'\n",
    "\n",
    "            instance[featkey] = addfeat\n",
    "#             break\n",
    "        pbar.update(1)\n",
    "#         break\n",
    "    pbar.close()\n",
    "\n",
    "    # modify the feature value\n",
    "    instances = feat_polished(instances) \n",
    "                \n",
    "    # convert the dict to tensor to learn the model\n",
    "    feat_dicts = []\n",
    "    for instance in instances:\n",
    "        # ensure the order is the same as in the later part\n",
    "        keys = sorted([key for key in instance.keys() if key.endswith(\"tweettext\")])\n",
    "        for key in keys:\n",
    "            featkey = key.split(\"_\")[0] + \"_addfeat\"\n",
    "            feat_dicts.append(instance[featkey])\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    feat_vectorized = dv.fit_transform(feat_dicts)\n",
    "    for index_outside, instance in enumerate(instances):\n",
    "        small_feats = feat_vectorized[index_outside * 7:(index_outside + 1) * 7]\n",
    "        # ensure the order is the same as the previous part\n",
    "        keys = sorted([key for key in instance.keys() if key.endswith(\"tweettext\")])\n",
    "        for index_inside, key in enumerate(keys):\n",
    "            newfeatkey = key.split(\"_\")[0] + \"_addfeattensor\"\n",
    "            feattensor = torch.FloatTensor(small_feats[index_inside]).unsqueeze(0).to('cpu')\n",
    "            instance[newfeatkey] = feattensor\n",
    "\n",
    "            \n",
    "    return instances\n",
    "\n",
    "# extract additional features\n",
    "print(\"Extracting additional features using SpaCy ...\")\n",
    "start_time = time.time()\n",
    "instances = add_additional_features(instances, mpqa_lexicon)\n",
    "end_time = time.time()\n",
    "elapsed_mins, elapsed_secs = learning_helper.epoch_time(start_time, end_time)\n",
    "print(f\"Time spent for SpaCy preprocessing: {elapsed_mins}m {elapsed_secs}s\")\n",
    "print(f\"additional feature dimension: {instances[0]['anchor_addfeattensor'].shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "train_instances, dev_instances, test_instances = preprocess.split_instances(instances)\n",
    "train_loader, dev_loader, test_loader = preprocess.get_data_loader(train_instances, dev_instances, test_instances, batch_size=batch_size)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# parameter setting\n",
    "bert_feat_dim = 768\n",
    "lstm_dim = 1024\n",
    "output_dim = 2\n",
    "hidden_dim = 512\n",
    "dropout_rate = 0.5\n",
    "\n",
    "\n",
    "class BertLstmTest(nn.Module):\n",
    "\n",
    "    def __init__(self, additional_feat_dim=0):\n",
    "        super(BertLstmTest, self).__init__()\n",
    "        self.bert_feat_dim = bert_feat_dim\n",
    "        self.additional_feat_dim = additional_feat_dim\n",
    "        self.lstm_dim = lstm_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.lstm = nn.LSTM(self.bert_feat_dim+self.additional_feat_dim, self.lstm_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc1 = nn.Linear(self.lstm_dim*2, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)       \n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, feat_combined):\n",
    "        \n",
    "        # get the bert output\n",
    "        context1_feat = feat_combined[:, :self.bert_feat_dim * 1].unsqueeze(1)\n",
    "        context2_feat = feat_combined[:, self.bert_feat_dim * 1:self.bert_feat_dim * 2].unsqueeze(1)\n",
    "        context3_feat = feat_combined[:, self.bert_feat_dim * 2:self.bert_feat_dim * 3].unsqueeze(1)\n",
    "        anchor_feat = feat_combined[:, self.bert_feat_dim * 3:self.bert_feat_dim * 4].unsqueeze(1)\n",
    "        context4_feat = feat_combined[:, self.bert_feat_dim * 4:self.bert_feat_dim * 5].unsqueeze(1)\n",
    "        context5_feat = feat_combined[:, self.bert_feat_dim * 5:self.bert_feat_dim * 6].unsqueeze(1)\n",
    "        context6_feat = feat_combined[:, self.bert_feat_dim * 6:self.bert_feat_dim * 7].unsqueeze(1)\n",
    "\n",
    "        # get the additional features\n",
    "        addfeat_dim = int((feat_combined.shape[1] - self.bert_feat_dim * 7) / 7)\n",
    "        context1_addfeat = feat_combined[:, self.bert_feat_dim * 7 + addfeat_dim * 0:self.bert_feat_dim * 7 + addfeat_dim * 1].unsqueeze(1)\n",
    "        context2_addfeat = feat_combined[:, self.bert_feat_dim * 7 + addfeat_dim * 1:self.bert_feat_dim * 7 + addfeat_dim * 2].unsqueeze(1)\n",
    "        context3_addfeat = feat_combined[:, self.bert_feat_dim * 7 + addfeat_dim * 2:self.bert_feat_dim * 7 + addfeat_dim * 3].unsqueeze(1)\n",
    "        anchor_addfeat = feat_combined[:, self.bert_feat_dim * 7 + addfeat_dim * 3:self.bert_feat_dim * 7 + addfeat_dim * 4].unsqueeze(1)\n",
    "        context4_addfeat = feat_combined[:, self.bert_feat_dim * 7 + addfeat_dim * 4:self.bert_feat_dim * 7 + addfeat_dim * 5].unsqueeze(1)\n",
    "        context5_addfeat = feat_combined[:, self.bert_feat_dim * 7 + addfeat_dim * 5:self.bert_feat_dim * 7 + addfeat_dim * 6].unsqueeze(1)\n",
    "        context6_addfeat = feat_combined[:, self.bert_feat_dim * 7 + addfeat_dim * 6:self.bert_feat_dim * 7 + addfeat_dim * 7].unsqueeze(1)\n",
    "\n",
    "        # prepare for the input of LSTM\n",
    "        lstm_input = torch.cat((\n",
    "            torch.cat((context1_feat, context1_addfeat), dim=2),\n",
    "            torch.cat((context2_feat, context2_addfeat), dim=2),\n",
    "            torch.cat((context3_feat, context3_addfeat), dim=2),\n",
    "            torch.cat((anchor_feat, anchor_addfeat), dim=2),\n",
    "#             anchor_feat,\n",
    "            torch.cat((context4_feat, context4_addfeat), dim=2),\n",
    "            torch.cat((context5_feat, context5_addfeat), dim=2),\n",
    "            torch.cat((context6_feat, context6_addfeat), dim=2),\n",
    "        ), dim=1)\n",
    "        \n",
    "        # pass the LSTM\n",
    "        lstm_output, _ = self.lstm(lstm_input)\n",
    "        \n",
    "# #         only take the last hidden state\n",
    "#         lstm_output = lstm_output[:, -1, :]\n",
    "\n",
    "        # global average pooling on the BiLSTM output\n",
    "        lstm_output = nn.AvgPool1d(7, 7)(lstm_output.permute(0,2,1)).permute(0,2,1).squeeze(1)\n",
    "                \n",
    "        # pass the fully-connected layer(s)\n",
    "        out = self.fc1(lstm_output)\n",
    "        out = F.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "# define the label mapping\n",
    "label_to_idx = {'Yes': 1, 'No': 0}\n",
    "idx_to_label = {1: 'Yes', 0: 'No'}\n",
    "    \n",
    "# define some global parameters\n",
    "learning_rate = 1e-05\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "additional_feat_dim = instances[0]['anchor_addfeattensor'].shape[1]\n",
    "classifier = BertLstmTest(additional_feat_dim=additional_feat_dim)\n",
    "classifier = classifier.to(device)\n",
    "\n",
    "# define the optimizer, loss function, and some parameters\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Epoch: 1 || Epoch Time: 0m 5s\n",
      "Epoch: 1 || Train loss: 0.08, Train Acc: 0.67\n",
      "Epoch: 1 || Dev loss: 0.08, Dev Acc: 0.68\n",
      "------------------------------------------------------------\n",
      "Epoch: 2 || Epoch Time: 0m 5s\n",
      "Epoch: 2 || Train loss: 0.08, Train Acc: 0.68\n",
      "Epoch: 2 || Dev loss: 0.08, Dev Acc: 0.68\n",
      "------------------------------------------------------------\n",
      "Epoch: 3 || Epoch Time: 0m 5s\n",
      "Epoch: 3 || Train loss: 0.08, Train Acc: 0.68\n",
      "Epoch: 3 || Dev loss: 0.08, Dev Acc: 0.68\n",
      "------------------------------------------------------------\n",
      "Epoch: 4 || Epoch Time: 0m 5s\n",
      "Epoch: 4 || Train loss: 0.08, Train Acc: 0.68\n",
      "Epoch: 4 || Dev loss: 0.08, Dev Acc: 0.68\n",
      "------------------------------------------------------------\n",
      "Epoch: 5 || Epoch Time: 0m 5s\n",
      "Epoch: 5 || Train loss: 0.08, Train Acc: 0.68\n",
      "Epoch: 5 || Dev loss: 0.08, Dev Acc: 0.68\n",
      "------------------------------------------------------------\n",
      "Epoch: 6 || Epoch Time: 0m 5s\n",
      "Epoch: 6 || Train loss: 0.08, Train Acc: 0.68\n",
      "Epoch: 6 || Dev loss: 0.08, Dev Acc: 0.68\n",
      "------------------------------------------------------------\n",
      "Epoch: 7 || Epoch Time: 0m 5s\n",
      "Epoch: 7 || Train loss: 0.08, Train Acc: 0.68\n",
      "Epoch: 7 || Dev loss: 0.08, Dev Acc: 0.68\n",
      "------------------------------------------------------------\n",
      "Epoch: 8 || Epoch Time: 0m 5s\n",
      "Epoch: 8 || Train loss: 0.08, Train Acc: 0.68\n",
      "Epoch: 8 || Dev loss: 0.08, Dev Acc: 0.68\n",
      "------------------------------------------------------------\n",
      "Epoch: 9 || Epoch Time: 0m 5s\n",
      "Epoch: 9 || Train loss: 0.08, Train Acc: 0.68\n",
      "Epoch: 9 || Dev loss: 0.08, Dev Acc: 0.68\n",
      "------------------------------------------------------------\n",
      "Epoch: 10 || Epoch Time: 0m 5s\n",
      "Epoch: 10 || Train loss: 0.08, Train Acc: 0.68\n",
      "Epoch: 10 || Dev loss: 0.08, Dev Acc: 0.68\n",
      "------------------------------------------------------------\n",
      "Epoch: 11 || Epoch Time: 0m 5s\n",
      "Epoch: 11 || Train loss: 0.08, Train Acc: 0.68\n",
      "Epoch: 11 || Dev loss: 0.08, Dev Acc: 0.68\n",
      "------------------------------------------------------------\n",
      "Epoch: 12 || Epoch Time: 0m 5s\n",
      "Epoch: 12 || Train loss: 0.08, Train Acc: 0.68\n",
      "Epoch: 12 || Dev loss: 0.08, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 13 || Epoch Time: 0m 5s\n",
      "Epoch: 13 || Train loss: 0.08, Train Acc: 0.68\n",
      "Epoch: 13 || Dev loss: 0.08, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 14 || Epoch Time: 0m 5s\n",
      "Epoch: 14 || Train loss: 0.08, Train Acc: 0.68\n",
      "Epoch: 14 || Dev loss: 0.08, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 15 || Epoch Time: 0m 5s\n",
      "Epoch: 15 || Train loss: 0.08, Train Acc: 0.68\n",
      "Epoch: 15 || Dev loss: 0.08, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 16 || Epoch Time: 0m 5s\n",
      "Epoch: 16 || Train loss: 0.08, Train Acc: 0.69\n",
      "Epoch: 16 || Dev loss: 0.08, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "The loss on development set does not decrease, stop training!\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.43      0.03      0.05       226\n",
      "         Yes       0.68      0.98      0.80       473\n",
      "\n",
      "    accuracy                           0.67       699\n",
      "   macro avg       0.55      0.50      0.43       699\n",
      "weighted avg       0.60      0.67      0.56       699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import evaluator\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "num_epochs = 500\n",
    "patience = 5\n",
    "best_valid_loss = float('inf')\n",
    "check_stopping = 0\n",
    "model_name = f'test_bert_lstm.pt'\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    start_time = time.time()\n",
    "    classifier.train()\n",
    "    train_loss, train_acc = learning_helper.train(classifier, train_loader, optimizer, criterion, device, label_to_idx)\n",
    "    dev_loss, dev_acc = learning_helper.evaluate(classifier, dev_loader, criterion, device, label_to_idx)\n",
    "    classifier.train()\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_mins, elapsed_secs = learning_helper.epoch_time(start_time, end_time)\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Epoch: {i+1} || Epoch Time: {elapsed_mins}m {elapsed_secs}s\")\n",
    "    print(f\"Epoch: {i+1} || Train loss: {train_loss:.02f}, Train Acc: {train_acc:.02f}\")\n",
    "    print(f\"Epoch: {i+1} || Dev loss: {dev_loss:.02f}, Dev Acc: {dev_acc:.02f}\")\n",
    "\n",
    "    # check if we need to save the model\n",
    "    if dev_loss < best_valid_loss:\n",
    "        check_stopping = 0\n",
    "        best_valid_loss = dev_loss\n",
    "#         torch.save(classifier.state_dict(), model_name)\n",
    "        torch.save(classifier.state_dict(), model_name)\n",
    "    else:\n",
    "        check_stopping += 1\n",
    "        print(f\"The loss on development set does not decrease\")\n",
    "        if check_stopping == patience:\n",
    "            print(\"The loss on development set does not decrease, stop training!\")\n",
    "            break\n",
    "            \n",
    "classifier.eval()\n",
    "pred_labels = evaluator.test_model(classifier, test_loader, idx_to_label, device)\n",
    "gold_labels = [x['adjudicated_label'] for x in test_instances]\n",
    "print('-' * 60)\n",
    "print(classification_report(gold_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(classifier.state_dict(), 'aa.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.43      0.25      0.32       226\n",
      "         Yes       0.70      0.84      0.76       473\n",
      "\n",
      "    accuracy                           0.65       699\n",
      "   macro avg       0.56      0.55      0.54       699\n",
      "weighted avg       0.61      0.65      0.62       699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the trained model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "additional_feat_dim = instances[0]['anchor_addfeattensor'].shape[1]\n",
    "temp_classifier = BertLstmTest(additional_feat_dim=additional_feat_dim)\n",
    "temp_classifier = temp_classifier.to(device)\n",
    "temp_classifier.load_state_dict(torch.load(model_name))\n",
    "\n",
    "temp_classifier.eval()\n",
    "pred_labels = evaluator.test_model(temp_classifier, test_loader, idx_to_label, device)\n",
    "gold_labels = [x['adjudicated_label'] for x in test_instances]\n",
    "print('-' * 60)\n",
    "print(classification_report(gold_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MPQA lexicon\n",
    "mpqa_path = os.path.join('data', 'reference', 'MPQA_Lexicon')\n",
    "mpqa_lexicon = preprocess.load_mpqa(mpqa_path)\n",
    "\n",
    "# extract additional features\n",
    "print(\"Extracting additional features using SpaCy ...\")\n",
    "start_time = time.time()\n",
    "instances = preprocess.add_additional_features(instances, mpqa_lexicon)\n",
    "end_time = time.time()\n",
    "elapsed_mins, elapsed_secs = learning_helper.epoch_time(start_time, end_time)\n",
    "print(f\"Time spent for SpaCy preprocessing: {elapsed_mins}m {elapsed_secs}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instances, dev_instances, test_instances = preprocess.split_instances(instances)\n",
    "train_loader, dev_loader, test_loader = preprocess.get_data_loader(train_instances, dev_instances, test_instances, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# parameter setting\n",
    "bert_feat_dim = 768\n",
    "lstm_dim = 512\n",
    "output_dim = 2\n",
    "hidden_dim = 512\n",
    "dropout_rate = 0.5\n",
    "\n",
    "\n",
    "class Test(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Test, self).__init__()\n",
    "        self.bert_feat_dim = bert_feat_dim\n",
    "        self.lstm_dim = lstm_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.lstm = nn.LSTM(self.bert_feat_dim, self.lstm_dim, batch_first=True, bidirectional=True)\n",
    "#         self.fc_combined = nn.Linear(self.bert_feat_dim*7+self.lstm_dim*2, hidden_dim)\n",
    "#         self.fc1 = nn.Linear(self.lstm_dim*2, hidden_dim)\n",
    "#         self.fc1 = nn.Linear(self.lstm_dim*2+self.bert_feat_dim, hidden_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim*3, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        # test\n",
    "        self.fc_lstm = nn.Linear(self.lstm_dim*2, self.hidden_dim)\n",
    "        self.fc_combined = nn.Linear(self.lstm_dim*2+self.bert_feat_dim, self.hidden_dim)\n",
    "        self.fc_anchor = nn.Linear(self.bert_feat_dim, self.hidden_dim)        \n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.bn = nn.BatchNorm1d(self.lstm_dim*2, affine=True)\n",
    "\n",
    "    def forward(self, feat_combined):\n",
    "        \n",
    "        # get the bert output\n",
    "        context1_feat = feat_combined[:, :self.bert_feat_dim * 1].unsqueeze(1)\n",
    "        context2_feat = feat_combined[:, self.bert_feat_dim * 1:self.bert_feat_dim * 2].unsqueeze(1)\n",
    "        context3_feat = feat_combined[:, self.bert_feat_dim * 2:self.bert_feat_dim * 3].unsqueeze(1)\n",
    "        anchor_feat = feat_combined[:, self.bert_feat_dim * 3:self.bert_feat_dim * 4].unsqueeze(1)\n",
    "        context4_feat = feat_combined[:, self.bert_feat_dim * 4:self.bert_feat_dim * 5].unsqueeze(1)\n",
    "        context5_feat = feat_combined[:, self.bert_feat_dim * 5:self.bert_feat_dim * 6].unsqueeze(1)\n",
    "        context6_feat = feat_combined[:, self.bert_feat_dim * 6:self.bert_feat_dim * 7].unsqueeze(1)\n",
    "\n",
    "        # get the additional features\n",
    "        addfeat_dim = int((feat_combined.shape[0] - self.bert_feat_dim * 7) / 7)\n",
    "        context1_addfeat = feat_combined[:, self.bert_feat_dim * 7 + addfeat_dim * 0:self.bert_feat_dim * 7 + addfeat_dim * 1].unsqueeze(1)\n",
    "        context2_addfeat = feat_combined[:, self.bert_feat_dim * 7 + addfeat_dim * 1:self.bert_feat_dim * 7 + addfeat_dim * 2].unsqueeze(1)\n",
    "        context3_addfeat = feat_combined[:, self.bert_feat_dim * 7 + addfeat_dim * 2:self.bert_feat_dim * 7 + addfeat_dim * 3].unsqueeze(1)\n",
    "        anchor_addfeat = feat_combined[:, self.bert_feat_dim * 7 + addfeat_dim * 3:self.bert_feat_dim * 7 + addfeat_dim * 4].unsqueeze(1)\n",
    "        context4_addfeat = feat_combined[:, self.bert_feat_dim * 7 + addfeat_dim * 4:self.bert_feat_dim * 7 + addfeat_dim * 5].unsqueeze(1)\n",
    "        context5_addfeat = feat_combined[:, self.bert_feat_dim * 7 + addfeat_dim * 5:self.bert_feat_dim * 7 + addfeat_dim * 6].unsqueeze(1)\n",
    "        context6_addfeat = feat_combined[:, self.bert_feat_dim * 7 + addfeat_dim * 6:self.bert_feat_dim * 7 + addfeat_dim * 7].unsqueeze(1)\n",
    "\n",
    "        # prepare for the input of LSTM\n",
    "        lstm_input = torch.cat((\n",
    "            context1_feat,\n",
    "            context2_feat,\n",
    "            context3_feat,\n",
    "#             anchor_feat,\n",
    "            context4_feat,\n",
    "            context5_feat,\n",
    "            context6_feat\n",
    "        ), dim=1)\n",
    "        \n",
    "        # pass the LSTM\n",
    "        lstm_output, _ = self.lstm(lstm_input)\n",
    "        \n",
    "        # only take the last hidden state\n",
    "#         out = out[:, -1, :]\n",
    "\n",
    "        # global maxpooling on the BiLSTM output\n",
    "        lstm_output = nn.AvgPool1d(6, 6)(lstm_output.permute(0,2,1)).permute(0,2,1).squeeze(1)\n",
    "        \n",
    "        combined_out = torch.cat((lstm_output, anchor_feat.squeeze(1)), dim=1)\n",
    "        \n",
    "        lstm_output = self.fc_lstm(lstm_output)\n",
    "        combined_out = self.fc_combined(combined_out)\n",
    "        anchor_feat = self.fc_anchor(anchor_feat).squeeze(1)\n",
    "        \n",
    "        all_combined = torch.cat((lstm_output, combined_out, anchor_feat), dim=1)\n",
    "        \n",
    "#         print(out.shape)\n",
    "        \n",
    "        # batch normalization\n",
    "#         out = self.bn(out)\n",
    "        \n",
    "        # pass the fully-connected layer(s)\n",
    "        out = self.fc1(all_combined)\n",
    "        out = F.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "# define the label mapping\n",
    "label_to_idx = {'Yes': 1, 'No': 0}\n",
    "idx_to_label = {1: 'Yes', 0: 'No'}\n",
    "    \n",
    "# define some global parameters\n",
    "num_epochs = 1000\n",
    "batch_size = 16\n",
    "patience = 10\n",
    "learning_rate = 1e-04\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "additional_feat_dim = train_instances[0]['anchor_addfeattensor'].shape[1]\n",
    "classifier = Test(additional_feat_dim=additional_feat_dim)\n",
    "classifier = classifier.to(device)\n",
    "\n",
    "# define the optimizer, loos function, and some parameters\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Epoch: 1 || Epoch Time: 0m 1s\n",
      "Epoch: 1 || Train loss: 0.04, Train Acc: 0.64\n",
      "Epoch: 1 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "------------------------------------------------------------\n",
      "Epoch: 2 || Epoch Time: 0m 2s\n",
      "Epoch: 2 || Train loss: 0.04, Train Acc: 0.65\n",
      "Epoch: 2 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "------------------------------------------------------------\n",
      "Epoch: 3 || Epoch Time: 0m 1s\n",
      "Epoch: 3 || Train loss: 0.04, Train Acc: 0.67\n",
      "Epoch: 3 || Dev loss: 0.04, Dev Acc: 0.67\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 4 || Epoch Time: 0m 1s\n",
      "Epoch: 4 || Train loss: 0.04, Train Acc: 0.69\n",
      "Epoch: 4 || Dev loss: 0.04, Dev Acc: 0.67\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 5 || Epoch Time: 0m 1s\n",
      "Epoch: 5 || Train loss: 0.04, Train Acc: 0.69\n",
      "Epoch: 5 || Dev loss: 0.04, Dev Acc: 0.67\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 6 || Epoch Time: 0m 1s\n",
      "Epoch: 6 || Train loss: 0.04, Train Acc: 0.70\n",
      "Epoch: 6 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 7 || Epoch Time: 0m 1s\n",
      "Epoch: 7 || Train loss: 0.04, Train Acc: 0.71\n",
      "Epoch: 7 || Dev loss: 0.04, Dev Acc: 0.67\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 8 || Epoch Time: 0m 1s\n",
      "Epoch: 8 || Train loss: 0.04, Train Acc: 0.72\n",
      "Epoch: 8 || Dev loss: 0.04, Dev Acc: 0.67\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 9 || Epoch Time: 0m 1s\n",
      "Epoch: 9 || Train loss: 0.03, Train Acc: 0.74\n",
      "Epoch: 9 || Dev loss: 0.04, Dev Acc: 0.67\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 10 || Epoch Time: 0m 1s\n",
      "Epoch: 10 || Train loss: 0.03, Train Acc: 0.75\n",
      "Epoch: 10 || Dev loss: 0.04, Dev Acc: 0.66\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 11 || Epoch Time: 0m 1s\n",
      "Epoch: 11 || Train loss: 0.03, Train Acc: 0.74\n",
      "Epoch: 11 || Dev loss: 0.04, Dev Acc: 0.66\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 12 || Epoch Time: 0m 1s\n",
      "Epoch: 12 || Train loss: 0.03, Train Acc: 0.77\n",
      "Epoch: 12 || Dev loss: 0.04, Dev Acc: 0.65\n",
      "The loss on development set does not decrease\n",
      "The loss on development set does not decrease, stop training!\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.35      0.07      0.11       226\n",
      "         Yes       0.68      0.94      0.79       473\n",
      "\n",
      "    accuracy                           0.66       699\n",
      "   macro avg       0.51      0.50      0.45       699\n",
      "weighted avg       0.57      0.66      0.57       699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import evaluator\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "num_epochs = 500\n",
    "patience = 10\n",
    "best_valid_loss = float('inf')\n",
    "check_stopping = 0\n",
    "model_name = f'retrained_{mode}_classifier.pt'\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    start_time = time.time()\n",
    "    classifier.train()\n",
    "    train_loss, train_acc = learning_helper.train(classifier, train_loader, optimizer, criterion, device, label_to_idx)\n",
    "    dev_loss, dev_acc = learning_helper.evaluate(classifier, dev_loader, criterion, device, label_to_idx)\n",
    "    classifier.train()\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_mins, elapsed_secs = learning_helper.epoch_time(start_time, end_time)\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Epoch: {i+1} || Epoch Time: {elapsed_mins}m {elapsed_secs}s\")\n",
    "    print(f\"Epoch: {i+1} || Train loss: {train_loss:.02f}, Train Acc: {train_acc:.02f}\")\n",
    "    print(f\"Epoch: {i+1} || Dev loss: {dev_loss:.02f}, Dev Acc: {dev_acc:.02f}\")\n",
    "\n",
    "    # check if we need to save the model\n",
    "    if dev_loss < best_valid_loss:\n",
    "        check_stopping = 0\n",
    "        best_valid_loss = dev_loss\n",
    "        torch.save(classifier.state_dict(), model_name)\n",
    "    else:\n",
    "        check_stopping += 1\n",
    "        print(f\"The loss on development set does not decrease\")\n",
    "        if check_stopping == patience:\n",
    "            print(\"The loss on development set does not decrease, stop training!\")\n",
    "            break\n",
    "            \n",
    "classifier.eval()\n",
    "pred_labels = evaluator.test_model(classifier, test_loader, idx_to_label, device)\n",
    "gold_labels = [x['adjudicated_label'] for x in test_instances]\n",
    "print('-' * 60)\n",
    "print(classification_report(gold_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Test:\n\tsize mismatch for fc1.weight: copying a param with shape torch.Size([2048, 16058]) from checkpoint, the shape in current model is torch.Size([2048, 5376]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-51f09920e5e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpred_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_to_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mgold_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'adjudicated_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_instances\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1045\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Test:\n\tsize mismatch for fc1.weight: copying a param with shape torch.Size([2048, 16058]) from checkpoint, the shape in current model is torch.Size([2048, 5376])."
     ]
    }
   ],
   "source": [
    "# load pretrained model\n",
    "classifier = Test()\n",
    "classifier = classifier.to(device)\n",
    "classifier.load_state_dict(torch.load(model_name))\n",
    "pred_labels = evaluator.test_model(classifier, test_loader, idx_to_label, device)\n",
    "gold_labels = [x['adjudicated_label'] for x in test_instances]\n",
    "print('-' * 60)\n",
    "print(classification_report(gold_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add more info to the annotation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "annotation_filepath = 'data/annotations/annotation_context.json'\n",
    "original_batch_filepath = 'batch_6540.csv'\n",
    "data_dir = 'data'\n",
    "\n",
    "lookup_dict = defaultdict(dict)\n",
    "with open(original_batch_filepath, 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        lookup_dict[row['instance_id']] = row\n",
    "        \n",
    "def add_info(lookup_dict, annotation_filepath):\n",
    "    instances = []\n",
    "    with open(annotation_filepath, 'r') as jsonfile:\n",
    "        lines = jsonfile.read().split(\"\\n\")[:-1]\n",
    "        for line in lines:\n",
    "            instance = {}\n",
    "            temp_instance = json.loads(line)\n",
    "            # remove \"Input.\" in the keys\n",
    "            for key, value in temp_instance.items():\n",
    "                if key.startswith(\"Input.\"):\n",
    "                    if not key.endswith(\"url\"):\n",
    "                        newkey = key.split(\".\")[-1]\n",
    "                        instance[newkey] = value\n",
    "                else:\n",
    "                    instance[key] = value\n",
    "\n",
    "            # add image filepath, json filepath, screenshot url, tweet_text, and timestamp\n",
    "            original_dict = lookup_dict[temp_instance['Input.instance_id']]\n",
    "            for key, value in original_dict.items():\n",
    "                if key.endswith(\"url\"):\n",
    "                    tweet_id = value.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0]\n",
    "\n",
    "                    # add json filepath\n",
    "                    jsonname = f\"anchor_{tweet_id}.json\" if 'anchor' in key else f\"{tweet_id}.json\"\n",
    "                    jsonpath = os.path.join(data_dir, 'json_files', '_'.join(value.split(\"/\")[-1].split(\"_\")[:2]), jsonname)\n",
    "                    jsonkey = key.split(\"_\")[0] + \"_jsonpath\"\n",
    "                    instance[jsonkey] = jsonpath\n",
    "\n",
    "                    # add tweet text\n",
    "                    with open(jsonpath, 'r') as tweetfile:\n",
    "                        tweet = json.loads(tweetfile.read())\n",
    "                    textkey = key.split(\"_\")[0] + \"_tweettext\"\n",
    "                    instance[textkey] = tweet['full_text']\n",
    "\n",
    "                    # add image filepath if image exists\n",
    "                    instance[key] = value\n",
    "                    imagename = f\"anchor_{tweet_id}.jpg\" if 'anchor' in key else f\"{tweet_id}.jpg\"\n",
    "                    imagepath = os.path.join(data_dir, 'image_files', '_'.join(value.split(\"/\")[-1].split(\"_\")[:2]), imagename)\n",
    "                    hasimg = os.path.isfile(imagepath)\n",
    "                    if hasimg:\n",
    "                        imagekey = key.split(\"_\")[0] + \"_imagepath\"\n",
    "                        instance[imagekey] = imagepath\n",
    "\n",
    "                if key.endswith(\"timestamp\"):\n",
    "                    instance[key] = original_dict[key]\n",
    "            instances.append(instance)\n",
    "    return instances\n",
    "\n",
    "instances = add_info(lookup_dict, annotation_filepath)\n",
    "\n",
    "new_annot_filename = 'new_annot.json'\n",
    "with open(new_annot_filename, 'w') as newjson:\n",
    "    for instance in instances:\n",
    "        newjson.write(json.dumps(instance))\n",
    "        newjson.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## copy the json file and image file to the loctmp2 folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import os\n",
    "from shutil import copyfile\n",
    "\n",
    "original_folder = '/media/zhaomin/Zhaomin_SSD/project_repo/emnlp2021/saved_tweets_original'\n",
    "data_dir = 'data'\n",
    "\n",
    "original_batch_filepath = 'batch_6540.csv'\n",
    "lookup_dict = defaultdict(dict)\n",
    "with open(original_batch_filepath, 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        lookup_dict[row['instance_id']] = row\n",
    "        \n",
    "annotation_filepath = 'data/annotations/annotation_context.json'\n",
    "with open(annotation_filepath, 'r') as jsonfile:\n",
    "    lines = jsonfile.read().split(\"\\n\")[:-1]\n",
    "    for line in lines:\n",
    "        instance = json.loads(line)\n",
    "        instance_id = instance['Input.instance_id']\n",
    "        \n",
    "        # create folder if it does not exist\n",
    "        if not os.path.isdir(os.path.join(data_dir, 'json_files', instance_id)):\n",
    "            os.mkdir(os.path.join(data_dir, 'json_files', instance_id))\n",
    "        if not os.path.isdir(os.path.join(data_dir, 'image_files', instance_id)):\n",
    "            os.mkdir(os.path.join(data_dir, 'image_files', instance_id))\n",
    "            \n",
    "        # find event path\n",
    "        original_dict = lookup_dict[instance_id]\n",
    "        event_name = re.split('(\\d+)', instance_id.split(\"_\")[0])[0]\n",
    "        for original_event in os.listdir(original_folder):\n",
    "            \n",
    "            # make sure the event and year are matched\n",
    "            if original_event.split(\"_\")[0] == event_name:\n",
    "                if original_event.split(\"_\")[1].split(\"-\")[0] == re.split('(\\d+)', instance_id.split(\"_\")[0])[1]:\n",
    "                    original_event_path = os.path.join(original_folder, original_event, f\"final_tweet_folder_{original_event}\", instance_id.split(\"_\")[-1])\n",
    "                    break\n",
    "        \n",
    "        for key, value in original_dict.items():\n",
    "            if key.endswith(\"url\"):\n",
    "                \n",
    "                if 'anchor' in key:\n",
    "                    real_instance_id = value.split(\"/\")[-1].split(\"_\")[1]\n",
    "                    src_jsonfilename = f\"anchor_{real_instance_id}.json\"\n",
    "                    src_imagefilename = f\"anchor_{real_instance_id}.jpg\"\n",
    "                    src_jsonfilepath = os.path.join(original_event_path, src_jsonfilename)\n",
    "                    src_imagefilepath = os.path.join(original_event_path, src_imagefilename)\n",
    "                    dst_jsonfilepath = os.path.join(data_dir, 'json_files', instance_id, src_jsonfilename)\n",
    "                    dst_imagefilepath = os.path.join(data_dir, 'image_files', instance_id, src_imagefilename)\n",
    "                    copyfile(src_jsonfilepath, dst_jsonfilepath)\n",
    "                    copyfile(src_imagefilepath, dst_imagefilepath)\n",
    "                \n",
    "                else:\n",
    "                    tweet_id = value.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1]\n",
    "                    \n",
    "                    # copy json file\n",
    "                    src_jsonfilename = f\"{tweet_id}.json\"\n",
    "                    src_jsonfilepath = os.path.join(original_event_path, src_jsonfilename)\n",
    "                    dst_jsonfilepath = os.path.join(data_dir, 'json_files', instance_id, src_jsonfilename)\n",
    "                    copyfile(src_jsonfilepath, dst_jsonfilepath)\n",
    "                    \n",
    "                    # copy image file if it exists\n",
    "                    src_imagefilename = f\"{tweet_id}.jpg\"\n",
    "                    if src_imagefilename in os.listdir(original_event_path):\n",
    "                        src_imagefilepath = os.path.join(original_event_path, src_imagefilename)\n",
    "                        dst_imagefilepath = os.path.join(data_dir, 'image_files', instance_id, src_imagefilename)\n",
    "                        copyfile(src_imagefilepath, dst_imagefilepath)\n",
    "                    \n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save split for replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = instances\n",
    "y = [x['adjudicated_label'] for x in instances]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y)\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, test_size=0.20, stratify=y_train)\n",
    "\n",
    "split = {'train': [x['instance_id'] for x in X_train],\n",
    "         'dev': [x['instance_id'] for x in X_dev],\n",
    "         'test': [x['instance_id'] for x in X_test]}\n",
    "\n",
    "with open(\"saved_split\", 'w') as splitfile:\n",
    "    splitfile.write(json.dumps(split))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stuff",
   "language": "python",
   "name": "jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
