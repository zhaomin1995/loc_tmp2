{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from utils import preprocess\n",
    "from utils import learning_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/annotations/new_annot.json'\n",
    "mode = 'anchor_text_image'\n",
    "\n",
    "instances = preprocess.load_data(data_dir, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for BERT: 0m 41s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "instances = preprocess.add_bert_output(instances, anchor_only=True)\n",
    "end_time = time.time()\n",
    "elapsed_mins, elapsed_secs = learning_helper.epoch_time(start_time, end_time)\n",
    "print(f\"Time spent for BERT: {elapsed_mins}m {elapsed_secs}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhaomin/envs/torch/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for VGG: 1m 17s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "instances = preprocess.add_vgg_output(instances, anchor_only=True)\n",
    "end_time = time.time()\n",
    "elapsed_mins, elapsed_secs = learning_helper.epoch_time(start_time, end_time)\n",
    "print(f\"Time spent for VGG: {elapsed_mins}m {elapsed_secs}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instances, dev_instances, test_instances = preprocess.split_instances(instances)\n",
    "train_loader, dev_loader, test_loader = preprocess.get_data_loader(train_instances, dev_instances, test_instances, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from utils import evaluator\n",
    "from sklearn.metrics import classification_report\n",
    "from model.anchor_text_image import AnchorTextImageModel\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# define the label mapping\n",
    "label_to_idx = {'Yes': 1, 'No': 0}\n",
    "idx_to_label = {1: 'Yes', 0: 'No'}\n",
    "\n",
    "# parameter setting\n",
    "bert_feat_dim = 768\n",
    "vgg_feat_dim = 1000\n",
    "output_dim = 2\n",
    "hidden_dim = 4096\n",
    "dropout_rate = 0.2\n",
    "learning_rate = 1e-03\n",
    "    \n",
    "# get the model based on mode and move model to GPU is GPU is available\n",
    "classifier = AnchorTextImageModel()\n",
    "classifier = classifier.to(device)\n",
    "\n",
    "# define the optimizer, loos function, and some parameters\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Epoch: 1 || Epoch Time: 0m 3s\n",
      "Epoch: 1 || Train loss: 0.10, Train Acc: 0.62\n",
      "Epoch: 1 || Dev loss: 0.04, Dev Acc: 0.67\n",
      "------------------------------------------------------------\n",
      "Epoch: 2 || Epoch Time: 0m 3s\n",
      "Epoch: 2 || Train loss: 0.04, Train Acc: 0.67\n",
      "Epoch: 2 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "------------------------------------------------------------\n",
      "Epoch: 3 || Epoch Time: 0m 3s\n",
      "Epoch: 3 || Train loss: 0.04, Train Acc: 0.66\n",
      "Epoch: 3 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 4 || Epoch Time: 0m 3s\n",
      "Epoch: 4 || Train loss: 0.04, Train Acc: 0.68\n",
      "Epoch: 4 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 5 || Epoch Time: 0m 3s\n",
      "Epoch: 5 || Train loss: 0.04, Train Acc: 0.68\n",
      "Epoch: 5 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 6 || Epoch Time: 0m 3s\n",
      "Epoch: 6 || Train loss: 0.04, Train Acc: 0.67\n",
      "Epoch: 6 || Dev loss: 0.05, Dev Acc: 0.35\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 7 || Epoch Time: 0m 3s\n",
      "Epoch: 7 || Train loss: 0.04, Train Acc: 0.67\n",
      "Epoch: 7 || Dev loss: 0.05, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 8 || Epoch Time: 0m 3s\n",
      "Epoch: 8 || Train loss: 0.04, Train Acc: 0.67\n",
      "Epoch: 8 || Dev loss: 0.04, Dev Acc: 0.67\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 9 || Epoch Time: 0m 3s\n",
      "Epoch: 9 || Train loss: 0.04, Train Acc: 0.67\n",
      "Epoch: 9 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 10 || Epoch Time: 0m 3s\n",
      "Epoch: 10 || Train loss: 0.04, Train Acc: 0.68\n",
      "Epoch: 10 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 11 || Epoch Time: 0m 3s\n",
      "Epoch: 11 || Train loss: 0.04, Train Acc: 0.68\n",
      "Epoch: 11 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 12 || Epoch Time: 0m 3s\n",
      "Epoch: 12 || Train loss: 0.04, Train Acc: 0.68\n",
      "Epoch: 12 || Dev loss: 0.04, Dev Acc: 0.67\n",
      "The loss on development set does not decrease\n",
      "The loss on development set does not decrease, stop training!\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00       226\n",
      "         Yes       0.68      1.00      0.81       473\n",
      "\n",
      "    accuracy                           0.68       699\n",
      "   macro avg       0.34      0.50      0.40       699\n",
      "weighted avg       0.46      0.68      0.55       699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "patience = 10\n",
    "best_valid_loss = float('inf')\n",
    "check_stopping = 0\n",
    "model_name = f'retrained_{mode}_classifier.pkl'\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc = learning_helper.train(classifier, train_loader, optimizer, criterion, device, label_to_idx)\n",
    "    dev_loss, dev_acc = learning_helper.evaluate(classifier, dev_loader, criterion, device, label_to_idx)\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_mins, elapsed_secs = learning_helper.epoch_time(start_time, end_time)\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Epoch: {i+1} || Epoch Time: {elapsed_mins}m {elapsed_secs}s\")\n",
    "    print(f\"Epoch: {i+1} || Train loss: {train_loss:.02f}, Train Acc: {train_acc:.02f}\")\n",
    "    print(f\"Epoch: {i+1} || Dev loss: {dev_loss:.02f}, Dev Acc: {dev_acc:.02f}\")\n",
    "\n",
    "    # check if we need to save the model\n",
    "    if dev_loss < best_valid_loss:\n",
    "        check_stopping = 0\n",
    "        best_valid_loss = dev_loss\n",
    "        torch.save(classifier, model_name)\n",
    "    else:\n",
    "        check_stopping += 1\n",
    "        print(f\"The loss on development set does not decrease\")\n",
    "        if check_stopping == patience:\n",
    "            print(\"The loss on development set does not decrease, stop training!\")\n",
    "            break\n",
    "            \n",
    "classifier.eval()\n",
    "pred_labels = evaluator.test_model(classifier, test_loader, idx_to_label, device)\n",
    "gold_labels = [x['adjudicated_label'] for x in test_instances]\n",
    "print('-' * 60)\n",
    "print(classification_report(gold_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## complicaed_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from utils import preprocess\n",
    "from utils import learning_helper\n",
    "\n",
    "data_dir = 'data/annotations/new_annot.json'\n",
    "mode = 'all_bert_only'\n",
    "\n",
    "instances = preprocess.load_data(data_dir, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 2608/3494 [03:20<01:11, 12.37it/s]"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "instances = preprocess.add_bert_output(instances, anchor_only=False)\n",
    "end_time = time.time()\n",
    "elapsed_mins, elapsed_secs = learning_helper.epoch_time(start_time, end_time)\n",
    "print(f\"Time spent for BERT: {elapsed_mins}m {elapsed_secs}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MPQA lexicon\n",
    "mpqa_path = os.path.join('data', 'reference', 'MPQA_Lexicon')\n",
    "mpqa_lexicon = preprocess.load_mpqa(mpqa_path)\n",
    "\n",
    "# extract additional features\n",
    "print(\"Extracting additional features using SpaCy ...\")\n",
    "start_time = time.time()\n",
    "instances = preprocess.add_additional_features(instances, mpqa_lexicon)\n",
    "end_time = time.time()\n",
    "elapsed_mins, elapsed_secs = learning_helper.epoch_time(start_time, end_time)\n",
    "print(f\"Time spent for SpaCy preprocessing: {elapsed_mins}m {elapsed_secs}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instances, dev_instances, test_instances = preprocess.split_instances(instances)\n",
    "train_loader, dev_loader, test_loader = preprocess.get_data_loader(train_instances, dev_instances, test_instances, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x. y in train_loader:\n",
    "    print(x.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import spacy\n",
    "import os\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "\n",
    "def add_additional_features(instances):\n",
    "    mpqa_path = os.path.join('data', 'reference', 'MPQA_Lexicon')\n",
    "    mpqa_lexicon = preprocess.load_mpqa(mpqa_path)\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    feat_dicts = []\n",
    "    for instance in instances:\n",
    "        # ensure the order is the same as in the later part\n",
    "        keys = sorted([key for key in instance.keys() if key.endswith(\"tweettext\")])\n",
    "        for key in keys:\n",
    "                \n",
    "            tweet = nlp(instance[key])\n",
    "#             print(tweet)\n",
    "            featkey = key.split(\"_\")[0] + \"_addfeat\"\n",
    "            addfeat = {}\n",
    "\n",
    "            # entirely uppercase words\n",
    "            num_uppercasewords = len(['x' for token in tweet if token.text.isupper()])\n",
    "            addfeat['num_uppercasewords'] = num_uppercasewords\n",
    "\n",
    "            # the number of URLs\n",
    "            num_urls = len(['x' for token in tweet if token.text.startswith(\"http\")])\n",
    "            addfeat['num_urls'] = num_urls\n",
    "\n",
    "            # the number of exclamation marks\n",
    "            num_exclamationmarks = len(['x' for token in tweet if token.text == '!'])\n",
    "            addfeat['num_exclamationmarks'] = num_exclamationmarks\n",
    "\n",
    "            # the number of strongly subjective words in MPQA lexicon\n",
    "            num_strongsubj = len([token for token in tweet if token.text in mpqa_lexicon['strongsubj']])\n",
    "            addfeat['num_strongsubj'] = num_strongsubj\n",
    "\n",
    "            # the number of weakly subjective words in MPQA lexicon\n",
    "            num_weaksubj = len([token for token in tweet if token.text in mpqa_lexicon['weaksubj']])\n",
    "            addfeat['num_weaksubj'] = num_weaksubj\n",
    "\n",
    "            #\n",
    "\n",
    "            instance[featkey] = addfeat\n",
    "            feat_dicts.append(addfeat)\n",
    "#             break\n",
    "#         break\n",
    "    \n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    feat_vectorized = dv.fit_transform(feat_dicts)\n",
    "    \n",
    "    for index_outside, instance in enumerate(instances):\n",
    "        small_feats = feat_vectorized[index_outside*7:(index_outside+1)*7]\n",
    "        # ensure the order is the same as the previous part\n",
    "        keys = sorted([key for key in instance.keys() if key.endswith(\"tweettext\")])\n",
    "        for index_inside, key in enumerate(keys):\n",
    "            newfeatkey = key.split(\"_\")[0] + \"_addfeattensor\"\n",
    "            feattensor = torch.FloatTensor(small_feats[index_inside]).unsqueeze(0).to('cpu')\n",
    "            instance[newfeatkey] = feattensor\n",
    "            \n",
    "    return instances\n",
    "\n",
    "temp_instances = instances.copy()\n",
    "new_instances = add_additional_features(temp_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_instances[0]['anchor_addfeattensor'].unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instances, dev_instances, test_instances = preprocess.split_instances(instances)\n",
    "train_loader, dev_loader, test_loader = preprocess.get_data_loader(train_instances, dev_instances, test_instances, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# parameter setting\n",
    "bert_feat_dim = 768\n",
    "lstm_dim = 512\n",
    "output_dim = 2\n",
    "hidden_dim = 512\n",
    "dropout_rate = 0.5\n",
    "\n",
    "\n",
    "class Test(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Test, self).__init__()\n",
    "        self.bert_feat_dim = bert_feat_dim\n",
    "        self.lstm_dim = lstm_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.lstm = nn.LSTM(self.bert_feat_dim, self.lstm_dim, batch_first=True, bidirectional=True)\n",
    "#         self.fc_combined = nn.Linear(self.bert_feat_dim*7+self.lstm_dim*2, hidden_dim)\n",
    "#         self.fc1 = nn.Linear(self.lstm_dim*2, hidden_dim)\n",
    "#         self.fc1 = nn.Linear(self.lstm_dim*2+self.bert_feat_dim, hidden_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim*3, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        # test\n",
    "        self.fc_lstm = nn.Linear(self.lstm_dim*2, self.hidden_dim)\n",
    "        self.fc_combined = nn.Linear(self.lstm_dim*2+self.bert_feat_dim, self.hidden_dim)\n",
    "        self.fc_anchor = nn.Linear(self.bert_feat_dim, self.hidden_dim)        \n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.bn = nn.BatchNorm1d(self.lstm_dim*2, affine=True)\n",
    "\n",
    "    def forward(self, feat_combined):\n",
    "        \n",
    "        # split the combined feature\n",
    "        context1_feat = feat_combined[:, :self.bert_feat_dim * 1].unsqueeze(1)\n",
    "        context2_feat = feat_combined[:, self.bert_feat_dim * 1:self.bert_feat_dim * 2].unsqueeze(1)\n",
    "        context3_feat = feat_combined[:, self.bert_feat_dim * 2:self.bert_feat_dim * 3].unsqueeze(1)\n",
    "        anchor_feat = feat_combined[:, self.bert_feat_dim * 3:self.bert_feat_dim * 4].unsqueeze(1)\n",
    "        context4_feat = feat_combined[:, self.bert_feat_dim * 4:self.bert_feat_dim * 5].unsqueeze(1)\n",
    "        context5_feat = feat_combined[:, self.bert_feat_dim * 5:self.bert_feat_dim * 6].unsqueeze(1)\n",
    "        context6_feat = feat_combined[:, self.bert_feat_dim * 6:self.bert_feat_dim * 7].unsqueeze(1)\n",
    "\n",
    "        # prepare for the input of LSTM\n",
    "        lstm_input = torch.cat((\n",
    "            context1_feat,\n",
    "            context2_feat,\n",
    "            context3_feat,\n",
    "#             anchor_feat,\n",
    "            context4_feat,\n",
    "            context5_feat,\n",
    "            context6_feat\n",
    "        ), dim=1)\n",
    "        \n",
    "        # pass the LSTM\n",
    "        lstm_output, _ = self.lstm(lstm_input)\n",
    "        \n",
    "        # only take the last hidden state\n",
    "#         out = out[:, -1, :]\n",
    "\n",
    "        # global maxpooling on the BiLSTM output\n",
    "        lstm_output = nn.AvgPool1d(6, 6)(lstm_output.permute(0,2,1)).permute(0,2,1).squeeze(1)\n",
    "        \n",
    "        combined_out = torch.cat((lstm_output, anchor_feat.squeeze(1)), dim=1)\n",
    "        \n",
    "        lstm_output = self.fc_lstm(lstm_output)\n",
    "        combined_out = self.fc_combined(combined_out)\n",
    "        anchor_feat = self.fc_anchor(anchor_feat).squeeze(1)\n",
    "        \n",
    "        all_combined = torch.cat((lstm_output, combined_out, anchor_feat), dim=1)\n",
    "        \n",
    "#         print(out.shape)\n",
    "        \n",
    "        # batch normalization\n",
    "#         out = self.bn(out)\n",
    "        \n",
    "        # pass the fully-connected layer(s)\n",
    "        out = self.fc1(all_combined)\n",
    "        out = F.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# define the label mapping\n",
    "label_to_idx = {'Yes': 1, 'No': 0}\n",
    "idx_to_label = {1: 'Yes', 0: 'No'}\n",
    "    \n",
    "# define some global parameters\n",
    "num_epochs = 1000\n",
    "batch_size = 16\n",
    "patience = 10\n",
    "learning_rate = 1e-03\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "classifier = Test()\n",
    "classifier = classifier.to(device)\n",
    "\n",
    "# define the optimizer, loos function, and some parameters\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Epoch: 1 || Epoch Time: 0m 0s\n",
      "Epoch: 1 || Train loss: 0.04, Train Acc: 0.64\n",
      "Epoch: 1 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "------------------------------------------------------------\n",
      "Epoch: 2 || Epoch Time: 0m 0s\n",
      "Epoch: 2 || Train loss: 0.04, Train Acc: 0.66\n",
      "Epoch: 2 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "------------------------------------------------------------\n",
      "Epoch: 3 || Epoch Time: 0m 0s\n",
      "Epoch: 3 || Train loss: 0.04, Train Acc: 0.67\n",
      "Epoch: 3 || Dev loss: 0.04, Dev Acc: 0.67\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 4 || Epoch Time: 0m 0s\n",
      "Epoch: 4 || Train loss: 0.04, Train Acc: 0.67\n",
      "Epoch: 4 || Dev loss: 0.04, Dev Acc: 0.67\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 5 || Epoch Time: 0m 0s\n",
      "Epoch: 5 || Train loss: 0.04, Train Acc: 0.67\n",
      "Epoch: 5 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "------------------------------------------------------------\n",
      "Epoch: 6 || Epoch Time: 0m 0s\n",
      "Epoch: 6 || Train loss: 0.04, Train Acc: 0.67\n",
      "Epoch: 6 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 7 || Epoch Time: 0m 0s\n",
      "Epoch: 7 || Train loss: 0.04, Train Acc: 0.67\n",
      "Epoch: 7 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 8 || Epoch Time: 0m 0s\n",
      "Epoch: 8 || Train loss: 0.04, Train Acc: 0.67\n",
      "Epoch: 8 || Dev loss: 0.04, Dev Acc: 0.67\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 9 || Epoch Time: 0m 0s\n",
      "Epoch: 9 || Train loss: 0.04, Train Acc: 0.68\n",
      "Epoch: 9 || Dev loss: 0.04, Dev Acc: 0.54\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 10 || Epoch Time: 0m 0s\n",
      "Epoch: 10 || Train loss: 0.04, Train Acc: 0.69\n",
      "Epoch: 10 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 11 || Epoch Time: 0m 0s\n",
      "Epoch: 11 || Train loss: 0.04, Train Acc: 0.68\n",
      "Epoch: 11 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 12 || Epoch Time: 0m 0s\n",
      "Epoch: 12 || Train loss: 0.04, Train Acc: 0.69\n",
      "Epoch: 12 || Dev loss: 0.04, Dev Acc: 0.67\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 13 || Epoch Time: 0m 0s\n",
      "Epoch: 13 || Train loss: 0.04, Train Acc: 0.69\n",
      "Epoch: 13 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 14 || Epoch Time: 0m 0s\n",
      "Epoch: 14 || Train loss: 0.04, Train Acc: 0.69\n",
      "Epoch: 14 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "------------------------------------------------------------\n",
      "Epoch: 15 || Epoch Time: 0m 0s\n",
      "Epoch: 15 || Train loss: 0.04, Train Acc: 0.68\n",
      "Epoch: 15 || Dev loss: 0.04, Dev Acc: 0.68\n",
      "The loss on development set does not decrease\n",
      "The loss on development set does not decrease, stop training!\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00       226\n",
      "         Yes       0.68      1.00      0.81       473\n",
      "\n",
      "    accuracy                           0.68       699\n",
      "   macro avg       0.34      0.50      0.40       699\n",
      "weighted avg       0.46      0.68      0.55       699\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhaomin/envs/torch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from utils import evaluator\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "num_epochs = 500\n",
    "patience = 10\n",
    "best_valid_loss = float('inf')\n",
    "check_stopping = 0\n",
    "model_name = f'retrained_{mode}_classifier.pt'\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    start_time = time.time()\n",
    "    classifier.train()\n",
    "    train_loss, train_acc = learning_helper.train(classifier, train_loader, optimizer, criterion, device, label_to_idx)\n",
    "    dev_loss, dev_acc = learning_helper.evaluate(classifier, dev_loader, criterion, device, label_to_idx)\n",
    "    classifier.train()\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_mins, elapsed_secs = learning_helper.epoch_time(start_time, end_time)\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Epoch: {i+1} || Epoch Time: {elapsed_mins}m {elapsed_secs}s\")\n",
    "    print(f\"Epoch: {i+1} || Train loss: {train_loss:.02f}, Train Acc: {train_acc:.02f}\")\n",
    "    print(f\"Epoch: {i+1} || Dev loss: {dev_loss:.02f}, Dev Acc: {dev_acc:.02f}\")\n",
    "\n",
    "    # check if we need to save the model\n",
    "    if dev_loss < best_valid_loss:\n",
    "        check_stopping = 0\n",
    "        best_valid_loss = dev_loss\n",
    "        torch.save(classifier.state_dict(), model_name)\n",
    "    else:\n",
    "        check_stopping += 1\n",
    "        print(f\"The loss on development set does not decrease\")\n",
    "        if check_stopping == patience:\n",
    "            print(\"The loss on development set does not decrease, stop training!\")\n",
    "            break\n",
    "            \n",
    "classifier.eval()\n",
    "pred_labels = evaluator.test_model(classifier, test_loader, idx_to_label, device)\n",
    "gold_labels = [x['adjudicated_label'] for x in test_instances]\n",
    "print('-' * 60)\n",
    "print(classification_report(gold_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.31      0.06      0.10       226\n",
      "         Yes       0.68      0.94      0.79       473\n",
      "\n",
      "    accuracy                           0.65       699\n",
      "   macro avg       0.49      0.50      0.44       699\n",
      "weighted avg       0.56      0.65      0.56       699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load pretrained model\n",
    "classifier = Test()\n",
    "classifier = classifier.to(device)\n",
    "classifier.load_state_dict(torch.load(model_name))\n",
    "pred_labels = evaluator.test_model(classifier, test_loader, idx_to_label, device)\n",
    "gold_labels = [x['adjudicated_label'] for x in test_instances]\n",
    "print('-' * 60)\n",
    "print(classification_report(gold_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add more info to the annotation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "annotation_filepath = 'data/annotations/annotation_context.json'\n",
    "original_batch_filepath = 'batch_6540.csv'\n",
    "data_dir = 'data'\n",
    "\n",
    "lookup_dict = defaultdict(dict)\n",
    "with open(original_batch_filepath, 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        lookup_dict[row['instance_id']] = row\n",
    "        \n",
    "def add_info(lookup_dict, annotation_filepath):\n",
    "    instances = []\n",
    "    with open(annotation_filepath, 'r') as jsonfile:\n",
    "        lines = jsonfile.read().split(\"\\n\")[:-1]\n",
    "        for line in lines:\n",
    "            instance = {}\n",
    "            temp_instance = json.loads(line)\n",
    "            # remove \"Input.\" in the keys\n",
    "            for key, value in temp_instance.items():\n",
    "                if key.startswith(\"Input.\"):\n",
    "                    if not key.endswith(\"url\"):\n",
    "                        newkey = key.split(\".\")[-1]\n",
    "                        instance[newkey] = value\n",
    "                else:\n",
    "                    instance[key] = value\n",
    "\n",
    "            # add image filepath, json filepath, screenshot url, tweet_text, and timestamp\n",
    "            original_dict = lookup_dict[temp_instance['Input.instance_id']]\n",
    "            for key, value in original_dict.items():\n",
    "                if key.endswith(\"url\"):\n",
    "                    tweet_id = value.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0]\n",
    "\n",
    "                    # add json filepath\n",
    "                    jsonname = f\"anchor_{tweet_id}.json\" if 'anchor' in key else f\"{tweet_id}.json\"\n",
    "                    jsonpath = os.path.join(data_dir, 'json_files', '_'.join(value.split(\"/\")[-1].split(\"_\")[:2]), jsonname)\n",
    "                    jsonkey = key.split(\"_\")[0] + \"_jsonpath\"\n",
    "                    instance[jsonkey] = jsonpath\n",
    "\n",
    "                    # add tweet text\n",
    "                    with open(jsonpath, 'r') as tweetfile:\n",
    "                        tweet = json.loads(tweetfile.read())\n",
    "                    textkey = key.split(\"_\")[0] + \"_tweettext\"\n",
    "                    instance[textkey] = tweet['full_text']\n",
    "\n",
    "                    # add image filepath if image exists\n",
    "                    instance[key] = value\n",
    "                    imagename = f\"anchor_{tweet_id}.jpg\" if 'anchor' in key else f\"{tweet_id}.jpg\"\n",
    "                    imagepath = os.path.join(data_dir, 'image_files', '_'.join(value.split(\"/\")[-1].split(\"_\")[:2]), imagename)\n",
    "                    hasimg = os.path.isfile(imagepath)\n",
    "                    if hasimg:\n",
    "                        imagekey = key.split(\"_\")[0] + \"_imagepath\"\n",
    "                        instance[imagekey] = imagepath\n",
    "\n",
    "                if key.endswith(\"timestamp\"):\n",
    "                    instance[key] = original_dict[key]\n",
    "            instances.append(instance)\n",
    "    return instances\n",
    "\n",
    "instances = add_info(lookup_dict, annotation_filepath)\n",
    "\n",
    "new_annot_filename = 'new_annot.json'\n",
    "with open(new_annot_filename, 'w') as newjson:\n",
    "    for instance in instances:\n",
    "        newjson.write(json.dumps(instance))\n",
    "        newjson.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## copy the json file and image file to the loctmp2 folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import os\n",
    "from shutil import copyfile\n",
    "\n",
    "original_folder = '/media/zhaomin/Zhaomin_SSD/project_repo/emnlp2021/saved_tweets_original'\n",
    "data_dir = 'data'\n",
    "\n",
    "original_batch_filepath = 'batch_6540.csv'\n",
    "lookup_dict = defaultdict(dict)\n",
    "with open(original_batch_filepath, 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        lookup_dict[row['instance_id']] = row\n",
    "        \n",
    "annotation_filepath = 'data/annotations/annotation_context.json'\n",
    "with open(annotation_filepath, 'r') as jsonfile:\n",
    "    lines = jsonfile.read().split(\"\\n\")[:-1]\n",
    "    for line in lines:\n",
    "        instance = json.loads(line)\n",
    "        instance_id = instance['Input.instance_id']\n",
    "        \n",
    "        # create folder if it does not exist\n",
    "        if not os.path.isdir(os.path.join(data_dir, 'json_files', instance_id)):\n",
    "            os.mkdir(os.path.join(data_dir, 'json_files', instance_id))\n",
    "        if not os.path.isdir(os.path.join(data_dir, 'image_files', instance_id)):\n",
    "            os.mkdir(os.path.join(data_dir, 'image_files', instance_id))\n",
    "            \n",
    "        # find event path\n",
    "        original_dict = lookup_dict[instance_id]\n",
    "        event_name = re.split('(\\d+)', instance_id.split(\"_\")[0])[0]\n",
    "        for original_event in os.listdir(original_folder):\n",
    "            \n",
    "            # make sure the event and year are matched\n",
    "            if original_event.split(\"_\")[0] == event_name:\n",
    "                if original_event.split(\"_\")[1].split(\"-\")[0] == re.split('(\\d+)', instance_id.split(\"_\")[0])[1]:\n",
    "                    original_event_path = os.path.join(original_folder, original_event, f\"final_tweet_folder_{original_event}\", instance_id.split(\"_\")[-1])\n",
    "                    break\n",
    "        \n",
    "        for key, value in original_dict.items():\n",
    "            if key.endswith(\"url\"):\n",
    "                \n",
    "                if 'anchor' in key:\n",
    "                    real_instance_id = value.split(\"/\")[-1].split(\"_\")[1]\n",
    "                    src_jsonfilename = f\"anchor_{real_instance_id}.json\"\n",
    "                    src_imagefilename = f\"anchor_{real_instance_id}.jpg\"\n",
    "                    src_jsonfilepath = os.path.join(original_event_path, src_jsonfilename)\n",
    "                    src_imagefilepath = os.path.join(original_event_path, src_imagefilename)\n",
    "                    dst_jsonfilepath = os.path.join(data_dir, 'json_files', instance_id, src_jsonfilename)\n",
    "                    dst_imagefilepath = os.path.join(data_dir, 'image_files', instance_id, src_imagefilename)\n",
    "                    copyfile(src_jsonfilepath, dst_jsonfilepath)\n",
    "                    copyfile(src_imagefilepath, dst_imagefilepath)\n",
    "                \n",
    "                else:\n",
    "                    tweet_id = value.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1]\n",
    "                    \n",
    "                    # copy json file\n",
    "                    src_jsonfilename = f\"{tweet_id}.json\"\n",
    "                    src_jsonfilepath = os.path.join(original_event_path, src_jsonfilename)\n",
    "                    dst_jsonfilepath = os.path.join(data_dir, 'json_files', instance_id, src_jsonfilename)\n",
    "                    copyfile(src_jsonfilepath, dst_jsonfilepath)\n",
    "                    \n",
    "                    # copy image file if it exists\n",
    "                    src_imagefilename = f\"{tweet_id}.jpg\"\n",
    "                    if src_imagefilename in os.listdir(original_event_path):\n",
    "                        src_imagefilepath = os.path.join(original_event_path, src_imagefilename)\n",
    "                        dst_imagefilepath = os.path.join(data_dir, 'image_files', instance_id, src_imagefilename)\n",
    "                        copyfile(src_imagefilepath, dst_imagefilepath)\n",
    "                    \n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save split for replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = instances\n",
    "y = [x['adjudicated_label'] for x in instances]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y)\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, test_size=0.20, stratify=y_train)\n",
    "\n",
    "split = {'train': [x['instance_id'] for x in X_train],\n",
    "         'dev': [x['instance_id'] for x in X_dev],\n",
    "         'test': [x['instance_id'] for x in X_test]}\n",
    "\n",
    "with open(\"saved_split\", 'w') as splitfile:\n",
    "    splitfile.write(json.dumps(split))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
