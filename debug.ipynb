{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2068c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d22a619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def load_data(data_filepath, split_filepath):\n",
    "    \n",
    "    train_data, test_data = [], []\n",
    "\n",
    "    with open(split_filepath, 'r') as file:\n",
    "        splits = json.load(file)\n",
    "        train_ids = splits['train']\n",
    "        test_ids = splits['test']\n",
    "        \n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            item = json.loads(line)\n",
    "            kept_annotations = [item[key] for key in item.keys() if key.startswith(\"Answer.Q1_\")]\n",
    "            if len(kept_annotations) == 0:\n",
    "                continue\n",
    "            texts = [\n",
    "                clean_text(item['context8_tweettext']),\n",
    "                clean_text(item['context9_tweettext']),\n",
    "                clean_text(item['context10_tweettext']),\n",
    "                clean_text(item['context11_tweettext']),\n",
    "                clean_text(item['context12_tweettext']),\n",
    "                clean_text(item['context13_tweettext']),\n",
    "            ]\n",
    "            instance = {'texts': texts, 'label': item['adjudicated_label'], 'location': item['anchor_location']}\n",
    "            if item['instance_id'] in train_ids:\n",
    "                train_data.append(instance)\n",
    "            if item['instance_id'] in test_ids:\n",
    "                test_data.append(instance)\n",
    "                \n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "data_filepath = 'data/data.json'\n",
    "split_filepath = 'data/data_split'\n",
    "train_data, test_data = load_data(data_filepath, split_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ee1969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45028ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f752f3dbd164a2d935bab75c7cedc37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 23.63 GiB total capacity; 22.38 GiB already allocated; 75.56 MiB free; 22.56 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModelForSeq2SeqLM, AutoTokenizer\n\u001b[1;32m      7\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgoogle/flan-ul2\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForSeq2SeqLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_in_8bit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n",
      "File \u001b[0;32m~/envs/llm/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:493\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    492\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 493\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    498\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    499\u001b[0m )\n",
      "File \u001b[0;32m~/envs/llm/lib/python3.10/site-packages/transformers/modeling_utils.py:2903\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2893\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2894\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   2896\u001b[0m     (\n\u001b[1;32m   2897\u001b[0m         model,\n\u001b[1;32m   2898\u001b[0m         missing_keys,\n\u001b[1;32m   2899\u001b[0m         unexpected_keys,\n\u001b[1;32m   2900\u001b[0m         mismatched_keys,\n\u001b[1;32m   2901\u001b[0m         offload_index,\n\u001b[1;32m   2902\u001b[0m         error_msgs,\n\u001b[0;32m-> 2903\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2904\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2905\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2906\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   2907\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2908\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2909\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2910\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2911\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2912\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2913\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2914\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2915\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_quantized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mload_in_8bit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2919\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2921\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_4bit \u001b[38;5;241m=\u001b[39m load_in_4bit\n\u001b[1;32m   2922\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_8bit \u001b[38;5;241m=\u001b[39m load_in_8bit\n",
      "File \u001b[0;32m~/envs/llm/lib/python3.10/site-packages/transformers/modeling_utils.py:3260\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m   3250\u001b[0m mismatched_keys \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m _find_mismatched_keys(\n\u001b[1;32m   3251\u001b[0m     state_dict,\n\u001b[1;32m   3252\u001b[0m     model_state_dict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3256\u001b[0m     ignore_mismatched_sizes,\n\u001b[1;32m   3257\u001b[0m )\n\u001b[1;32m   3259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m low_cpu_mem_usage:\n\u001b[0;32m-> 3260\u001b[0m     new_error_msgs, offload_index, state_dict_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3267\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3268\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_quantized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_quantized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3275\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3276\u001b[0m     error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_error_msgs\n\u001b[1;32m   3277\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/envs/llm/lib/python3.10/site-packages/transformers/modeling_utils.py:725\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, loaded_state_dict_keys, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, is_quantized, is_safetensors, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m    722\u001b[0m             fp16_statistics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    724\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSCB\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m param_name:\n\u001b[0;32m--> 725\u001b[0m             \u001b[43mset_module_quantized_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp16_statistics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfp16_statistics\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m error_msgs, offload_index, state_dict_index\n",
      "File \u001b[0;32m~/envs/llm/lib/python3.10/site-packages/transformers/utils/bitsandbytes.py:97\u001b[0m, in \u001b[0;36mset_module_quantized_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, fp16_statistics)\u001b[0m\n\u001b[1;32m     95\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m old_value\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_8bit:\n\u001b[0;32m---> 97\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mbnb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInt8Params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_4bit:\n\u001b[1;32m     99\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m bnb\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mParams4bit(new_value, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/envs/llm/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:333\u001b[0m, in \u001b[0;36mInt8Params.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m device, dtype, non_blocking, convert_to_format \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39m_parse_to(\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    326\u001b[0m )\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    329\u001b[0m     device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m device\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    332\u001b[0m ):\n\u001b[0;32m--> 333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    335\u001b[0m     new_param \u001b[38;5;241m=\u001b[39m Int8Params(\n\u001b[1;32m    336\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m    337\u001b[0m             device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mdtype, non_blocking\u001b[38;5;241m=\u001b[39mnon_blocking\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    340\u001b[0m         has_fp16_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_fp16_weights,\n\u001b[1;32m    341\u001b[0m     )\n",
      "File \u001b[0;32m~/envs/llm/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:296\u001b[0m, in \u001b[0;36mInt8Params.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcuda(device)\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;66;03m# we store the 8-bit rows-major weight\u001b[39;00m\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;66;03m# we convert this weight to the turning/ampere weight during the first inference pass\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m     B \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhalf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m     CB, CBt, SCB, SCBt, coo_tensorB \u001b[38;5;241m=\u001b[39m bnb\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdouble_quant(B)\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m CBt\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 23.63 GiB total capacity; 22.38 GiB already allocated; 75.56 MiB free; 22.56 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model_name = 'google/flan-ul2'\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, load_in_8bit=True).to('cuda:2')\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27f8fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = \"\"\"### Prompt: Read the tweets below and determine its sentiment.\n",
    "### Tweets: Dallas is so bad.\n",
    "OPTIONS:\n",
    "1. Negative\n",
    "2. Positive\n",
    "### Answer: \"\"\"\n",
    "\n",
    "inputs = tokenizer(model_input, return_tensors=\"pt\").to(model.device)\n",
    "outputs = model.generate(**inputs)\n",
    "print(tokenizer.batch_decode(outputs, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa7b979",
   "metadata": {},
   "source": [
    "### Test UL2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a6393b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7636c5b068441e1a0aa4ec664bc1585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/ul2\", load_in_8bit=True, device_map='auto')                                                                                                   \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/ul2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "458a787e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of United States is Donald Trump. Question: Who is the president of India? Answer: The president of India is Ram Nath Kovind. Question: Who is the president of Pakistan? Answer: The president of Pakistan is Imran Khan. Question: Who is the president of Bangladesh? Answer: The president of Bangladesh is Abdullah Ahmed. Question: Who is the president of Bangladesh? Answer: The president of Bangladesh is Sheikh Hasina. Question: Who is the\n"
     ]
    }
   ],
   "source": [
    "input_string = (\n",
    "    \"[NLG] What is the president of United States?\\nAnswer: \"\n",
    ")                                          \n",
    "\n",
    "inputs = tokenizer(input_string, return_tensors=\"pt\", add_special_tokens=False).input_ids.to(model.device)\n",
    "\n",
    "outputs = model.generate(inputs, max_length=100)\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea3f839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a1ee178",
   "metadata": {},
   "source": [
    "### Test various model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99716a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"declare-lab/flan-alpaca-xxl\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"declare-lab/flan-alpaca-xxl\",\n",
    "                                              load_in_8bit=True, \n",
    "                                              device_map=\"auto\",\n",
    "                                              trust_remote_code=True,\n",
    "                                              cache_dir='/mnt/DATA/hf_cache/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7cc9dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2. Negative'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sent = 'Dallas is so bad and I really wanna go back in the future'\n",
    "prompt = f\"\"\"Determine the sentiment of the given sentence.\n",
    "\n",
    "{test_sent}\n",
    "\n",
    "OPTIONS:\n",
    "1. Positive.\n",
    "2. Negative.\n",
    "ANSWER: \"\"\"\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
    "output_tokens = model.generate(**input_ids, max_new_tokens=150, do_sample=False, use_cache=True)\n",
    "decoded_output = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
    "decoded_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58409b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f21fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ab38be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2aa636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "759e0777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 KB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.5.0 in /home/UNT/zx0034/envs/llm/lib/python3.10/site-packages (from scikit-learn) (1.11.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/UNT/zx0034/envs/llm/lib/python3.10/site-packages (from scikit-learn) (1.25.2)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.3.0 threadpoolctl-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "687355e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flan_alpaca_all_five-shot_result | Accuracy: 0.35 | F1: 0.46\n",
      "flan_alpaca_all_one-shot_result | Accuracy: 0.35 | F1: 0.49\n",
      "flan_alpaca_all_ten-shot_result | Accuracy: 0.37 | F1: 0.46\n",
      "flan_alpaca_all_zero-shot_result | Accuracy: 0.33 | F1: 0.50\n",
      "flan_alpaca_early_target_five-shot_result | Accuracy: 0.35 | F1: 0.47\n",
      "flan_alpaca_early_target_one-shot_result | Accuracy: 0.34 | F1: 0.49\n",
      "flan_alpaca_early_target_ten-shot_result | Accuracy: 0.35 | F1: 0.46\n",
      "flan_alpaca_early_target_zero-shot_result | Accuracy: 0.33 | F1: 0.50\n",
      "flan_alpaca_target_five-shot_result | Accuracy: 0.34 | F1: 0.49\n",
      "flan_alpaca_target_later_five-shot_result | Accuracy: 0.34 | F1: 0.46\n",
      "flan_alpaca_target_later_one-shot_result | Accuracy: 0.34 | F1: 0.48\n",
      "flan_alpaca_target_later_ten-shot_result | Accuracy: 0.34 | F1: 0.45\n",
      "flan_alpaca_target_later_zero-shot_result | Accuracy: 0.33 | F1: 0.50\n",
      "flan_alpaca_target_one-shot_result | Accuracy: 0.34 | F1: 0.49\n",
      "flan_alpaca_target_ten-shot_result | Accuracy: 0.34 | F1: 0.48\n",
      "flan_alpaca_target_zero-shot_result | Accuracy: 0.33 | F1: 0.50\n",
      "flan_t5_all_five-shot_result | Accuracy: 0.41 | F1: 0.46\n",
      "flan_t5_all_one-shot_result | Accuracy: 0.39 | F1: 0.45\n",
      "flan_t5_all_ten-shot_result | Accuracy: 0.40 | F1: 0.46\n",
      "flan_t5_all_zero-shot_result | Accuracy: 0.36 | F1: 0.47\n",
      "flan_t5_early_target_five-shot_result | Accuracy: 0.38 | F1: 0.44\n",
      "flan_t5_early_target_one-shot_result | Accuracy: 0.38 | F1: 0.45\n",
      "flan_t5_early_target_ten-shot_result | Accuracy: 0.37 | F1: 0.45\n",
      "flan_t5_early_target_zero-shot_result | Accuracy: 0.35 | F1: 0.46\n",
      "flan_t5_target_five-shot_result | Accuracy: 0.35 | F1: 0.47\n",
      "flan_t5_target_later_five-shot_result | Accuracy: 0.37 | F1: 0.45\n",
      "flan_t5_target_later_one-shot_result | Accuracy: 0.38 | F1: 0.46\n",
      "flan_t5_target_later_ten-shot_result | Accuracy: 0.36 | F1: 0.46\n",
      "flan_t5_target_later_zero-shot_result | Accuracy: 0.35 | F1: 0.46\n",
      "flan_t5_target_one-shot_result | Accuracy: 0.36 | F1: 0.47\n",
      "flan_t5_target_ten-shot_result | Accuracy: 0.35 | F1: 0.48\n",
      "flan_t5_target_zero-shot_result | Accuracy: 0.36 | F1: 0.49\n",
      "flan_ul2_all_five-shot_result | Accuracy: 0.48 | F1: 0.48\n",
      "flan_ul2_all_one-shot_result | Accuracy: 0.49 | F1: 0.48\n",
      "flan_ul2_all_ten-shot_result | Accuracy: 0.49 | F1: 0.49\n",
      "flan_ul2_all_zero-shot_result | Accuracy: 0.49 | F1: 0.48\n",
      "flan_ul2_early_target_five-shot_result | Accuracy: 0.45 | F1: 0.46\n",
      "flan_ul2_early_target_one-shot_result | Accuracy: 0.46 | F1: 0.47\n",
      "flan_ul2_early_target_ten-shot_result | Accuracy: 0.45 | F1: 0.46\n",
      "flan_ul2_early_target_zero-shot_result | Accuracy: 0.48 | F1: 0.48\n",
      "flan_ul2_target_five-shot_result | Accuracy: 0.40 | F1: 0.44\n",
      "flan_ul2_target_later_five-shot_result | Accuracy: 0.44 | F1: 0.46\n",
      "flan_ul2_target_later_one-shot_result | Accuracy: 0.45 | F1: 0.46\n",
      "flan_ul2_target_later_ten-shot_result | Accuracy: 0.44 | F1: 0.46\n",
      "flan_ul2_target_later_zero-shot_result | Accuracy: 0.46 | F1: 0.47\n",
      "flan_ul2_target_one-shot_result | Accuracy: 0.40 | F1: 0.44\n",
      "flan_ul2_target_ten-shot_result | Accuracy: 0.40 | F1: 0.44\n",
      "flan_ul2_target_zero-shot_result | Accuracy: 0.41 | F1: 0.45\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "response_folder = 'output/results/'\n",
    "for response_filename in sorted(os.listdir(response_folder)):\n",
    "    response_filepath = os.path.join(response_folder, response_filename)\n",
    "    with open(response_filepath, 'r') as file:\n",
    "        response = json.load(file)\n",
    "#     print(\"#\" * 60)\n",
    "#     print(\"#\" * 10 + \"  \" + response_filename + \"  \" + \"#\" * 10)\n",
    "    print(f\"{response_filename} | Accuracy: {response['accuracy']:.2f} | F1: {response['weighted avg']['f1-score']:.2f}\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffe929c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# flan_t5 + target\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_t5 -input_content target -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar zero-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_t5 -input_content target -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar one-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_t5 -input_content target -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar five-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_t5 -input_content target -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar ten-shot\n",
      "\n",
      "# flan_t5 + early_target\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_t5 -input_content early_target -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar zero-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_t5 -input_content early_target -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar one-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_t5 -input_content early_target -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar five-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_t5 -input_content early_target -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar ten-shot\n",
      "\n",
      "# flan_t5 + target_later\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_t5 -input_content target_later -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar zero-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_t5 -input_content target_later -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar one-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_t5 -input_content target_later -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar five-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_t5 -input_content target_later -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar ten-shot\n",
      "\n",
      "# flan_t5 + all\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_t5 -input_content all -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar zero-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_t5 -input_content all -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar one-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_t5 -input_content all -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar five-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_t5 -input_content all -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar ten-shot\n",
      "\n",
      "\n",
      "# flan_ul2 + target\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_ul2 -input_content target -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar zero-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_ul2 -input_content target -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar one-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_ul2 -input_content target -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar five-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_ul2 -input_content target -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar ten-shot\n",
      "\n",
      "# flan_ul2 + early_target\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_ul2 -input_content early_target -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar zero-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_ul2 -input_content early_target -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar one-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_ul2 -input_content early_target -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar five-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_ul2 -input_content early_target -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar ten-shot\n",
      "\n",
      "# flan_ul2 + target_later\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_ul2 -input_content target_later -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar zero-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_ul2 -input_content target_later -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar one-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_ul2 -input_content target_later -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar five-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_ul2 -input_content target_later -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar ten-shot\n",
      "\n",
      "# flan_ul2 + all\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_ul2 -input_content all -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar zero-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_ul2 -input_content all -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar one-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_ul2 -input_content all -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar five-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_ul2 -input_content all -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar ten-shot\n",
      "\n",
      "\n",
      "# flan_alpaca + target\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_alpaca -input_content target -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar zero-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_alpaca -input_content target -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar one-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_alpaca -input_content target -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar five-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_alpaca -input_content target -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar ten-shot\n",
      "\n",
      "# flan_alpaca + early_target\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_alpaca -input_content early_target -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar zero-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_alpaca -input_content early_target -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar one-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_alpaca -input_content early_target -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar five-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_alpaca -input_content early_target -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar ten-shot\n",
      "\n",
      "# flan_alpaca + target_later\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_alpaca -input_content target_later -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar zero-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_alpaca -input_content target_later -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar one-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_alpaca -input_content target_later -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar five-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_alpaca -input_content target_later -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar ten-shot\n",
      "\n",
      "# flan_alpaca + all\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_alpaca -input_content all -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar zero-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_alpaca -input_content all -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar one-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_alpaca -input_content all -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar five-shot\n",
      "CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment flan_alpaca -input_content all -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar ten-shot\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = ['flan_t5', 'flan_ul2', 'flan_alpaca']\n",
    "inputs = ['target', 'early_target', 'target_later', 'all']\n",
    "shots = ['zero-shot', 'one-shot', 'five-shot', 'ten-shot']\n",
    "for model in models:\n",
    "    for input_ in inputs:\n",
    "        print(f'# {model} + {input_}')\n",
    "        for shot in shots:\n",
    "            command = f'CUDA_VISIBLE_DEVICES=0 python llm.py -data_dir data/ -experiment {model} -input_content {input_} -output_dir output -cache_dir /mnt/DATA/hf_cache/ -exemplar {shot}'\n",
    "            print(command)\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce648974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d98f533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e15df75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07ff24b2",
   "metadata": {},
   "source": [
    "## ChatGPT experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c75dd112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from utils.data import load_data, get_prompt\n",
    "from datasets import Dataset\n",
    "\n",
    "data_dir = 'data/'\n",
    "input_content = 'all'\n",
    "exemplar = 'ten-shot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8450584",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filepath = os.path.join(data_dir, 'data.json')\n",
    "split_filepath = os.path.join(data_dir, 'data_split')\n",
    "train_data, test_data = load_data(data_filepath, split_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1822a716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the training prompts and test prompts\n",
    "train_samples = Dataset.from_dict({\n",
    "    'text': [get_prompt(instance, input_content, data_type='train', exemplar=exemplar) for instance in train_data]\n",
    "})\n",
    "test_samples = Dataset.from_dict({\n",
    "    'text': [get_prompt(instance, input_content, data_type='test', exemplar=exemplar) for instance in test_data],\n",
    "    'label': [instance['label'] for instance in test_data]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6b9a2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"### Instruction: Read the tweets chronologically published and determine if the author of the tweet is located in Dallas when the tweet was published. The '#' in the hashtags and '@' in the mentions are removed. Please select the number listed below.\\n\\nOne thing that has surprised me since moving to Dallas is how beautiful the Texas sky can be.\\n\\nOPTIONS:\\n1. Yes.\\n2. I cannot determine if the author of the tweet is located in Dallas when the tweet was published.\\nAnswer: 1.\\n\\nRead the tweets chronologically published and determine if the author of the tweet is located in Dallas when the tweet was published. The '#' in the hashtags and '@' in the mentions are removed. Please select the number listed below.\\n\\nbreaking news: the seattle kraken are being removed from the nhl because the booktok fans are done with them. rip seattle kraken 2021-2023\\n\\nOPTIONS:\\n1. Yes.\\n2. I cannot determine if the author of the tweet is located in Seattle when the tweet was published.\\nAnswer: 2.\\n\\nRead the tweets chronologically published and determine if the author of the tweet is located in Dallas when the tweet was published. The '#' in the hashtags and '@' in the mentions are removed. Please select the number listed below.\\n\\nMemorial Day Weekend kickoff nachos with MikeBagarella. Top 1 nachos in Boston 💙\\n\\nOPTIONS:\\n1. Yes.\\n2. I cannot determine if the author of the tweet is located in Boston when the tweet was published.\\nAnswer: 1.\\n\\nRead the tweets chronologically published and determine if the author of the tweet is located in Dallas when the tweet was published. The '#' in the hashtags and '@' in the mentions are removed. Please select the number listed below.\\n\\nHiiiii we are live! I did some Christmas themed makeup. Come hang out ❤️❤️ PhoenixCartel \\n\\nOPTIONS:\\n1. Yes.\\n2. I cannot determine if the author of the tweet is located in Phoenix when the tweet was published.\\nAnswer: 1.\\n\\nRead the tweets chronologically published and determine if the author of the tweet is located in Dallas when the tweet was published. The '#' in the hashtags and '@' in the mentions are removed. Please select the number listed below.\\n\\nFlew to Portland, Oregon to be with my sister-in-law, Estrellita Mendez and her family for Christmas.  I am so glad I did!\\n\\nOPTIONS:\\n1. Yes.\\n2. I cannot determine if the author of the tweet is located in Portland when the tweet was published.\\nAnswer: 1.\\n\\nRead the tweets chronologically published and determine if the author of the tweet is located in Dallas when the tweet was published. The '#' in the hashtags and '@' in the mentions are removed. Please select the number listed below.\\n\\nPulling up to the airport for our 3rd trip to Dallas this month. We are locked in and ready to go handle business on the road ✈️\\n\\nOPTIONS:\\n1. Yes.\\n2. I cannot determine if the author of the tweet is located in Dallas when the tweet was published.\\nAnswer: 1.\\n\\nRead the tweets chronologically published and determine if the author of the tweet is located in Dallas when the tweet was published. The '#' in the hashtags and '@' in the mentions are removed. Please select the number listed below.\\n\\ndriving to dallas. hope i have some inquiries when i get there\\n\\nOPTIONS:\\n1. Yes.\\n2. I cannot determine if the author of the tweet is located in Dallas when the tweet was published.\\nAnswer: 2.\\n\\nRead the tweets chronologically published and determine if the author of the tweet is located in Dallas when the tweet was published. The '#' in the hashtags and '@' in the mentions are removed. Please select the number listed below.\\n\\nTrip to Dallas w my princess ❤️\\n\\nOPTIONS:\\n1. Yes.\\n2. I cannot determine if the author of the tweet is located in Dallas when the tweet was published.\\nAnswer: 1.\\n\\nRead the tweets chronologically published and determine if the author of the tweet is located in Dallas when the tweet was published. The '#' in the hashtags and '@' in the mentions are removed. Please select the number listed below.\\n\\nDallas is so beautiful. Right outside my house this exists. In between an old k-mart and a Highway of course.\\n\\nOPTIONS:\\n1. Yes.\\n2. I cannot determine if the author of the tweet is located in Seattle when the tweet was published.\\nAnswer: 1.\\n\\nRead the tweets chronologically published and determine if the author of the tweet is located in Dallas when the tweet was published. The '#' in the hashtags and '@' in the mentions are removed. Please select the number listed below.\\n\\na beautiful sunset from East Boston Massachusett ❤️\\n\\nOPTIONS:\\n1. Yes.\\n2. I cannot determine if the author of the tweet is located in Boston when the tweet was published.\\nAnswer: 1.\\n### Prompt: Read the tweets chronologically published and determine if the author of the tweet is located at Atlanta when the tweet was published. The '#' in the hashtags and '@' in the mentions are removed. Please select the number listed below and justify your answer.\\n\\nTWEET 1:\\naungeliquefox5 Yes! And so generous !\\n\\nTWEET 2:\\nAlexaLiackoFOX5 YOU NAME IT!!!!\\n\\nTWEET 3:\\nYES! I am SO happy for Celine. She has one of the greatest voices in music. And she's been through so much. No one deserves this more!\\n\\nTWEET 4:\\nMood when I saw FOX5ATLCallaway slicing our FOX5Atlanta Thanksgiving Eve Turkey!!! YAAASSSSSS!!!\\n\\nTWEET 5:\\nCityStonecrest FOX5ATLCallaway Elepo FOX5Atlanta GONE!!! LOL\\n\\nTWEET 6:\\nI have SO much to be thankful for! Take time to spend this holiday with the people you love. FOX5Atlanta\\n\\nOPTIONS:\\n1. Yes.\\n2. I cannot determine if the author of the tweet is located at Atlanta when the tweet was published.\\nANSWER: \""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_samples['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462515fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94bc913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import time\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "output_dir = 'output/results/'\n",
    "output_filename = f\"gpt4_{input_content}_{exemplar}_outputs.json\"\n",
    "output_filepath = os.path.join(output_dir, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01618bba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "587cf3238397481381c7e6ae011df693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pbar = tqdm(total=len(test_samples['text']))\n",
    "\n",
    "if os.path.isfile(output_filepath):\n",
    "    with open(output_filepath, 'r') as file:\n",
    "        processed_ids = set([json.loads(line)['id'] for line in file.read().splitlines()])\n",
    "else:\n",
    "    processed_ids = set()\n",
    "\n",
    "with open(output_filepath, 'a+') as file:\n",
    "    \n",
    "    for index, prompt in enumerate(test_samples['text']):\n",
    "\n",
    "        if str(index) in processed_ids:\n",
    "            pbar.update(1)\n",
    "            continue\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "          model=\"gpt-4-0613\",\n",
    "          messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "\n",
    "        response = response.to_dict()\n",
    "        response['id'] = str(index)\n",
    "        file.write(json.dumps(response) + '\\n')\n",
    "\n",
    "        time.sleep(10)\n",
    "        pbar.update(1)\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80b91811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'799',\n",
       " '810',\n",
       " '917',\n",
       " '229',\n",
       " '641',\n",
       " '319',\n",
       " '37',\n",
       " '247',\n",
       " '346',\n",
       " '595',\n",
       " '219',\n",
       " '1001',\n",
       " '137',\n",
       " '460',\n",
       " '391',\n",
       " '71',\n",
       " '173',\n",
       " '299',\n",
       " '629',\n",
       " '428',\n",
       " '531',\n",
       " '626',\n",
       " '669',\n",
       " '69',\n",
       " '737',\n",
       " '740',\n",
       " '88',\n",
       " '753',\n",
       " '110',\n",
       " '750',\n",
       " '183',\n",
       " '913',\n",
       " '492',\n",
       " '369',\n",
       " '409',\n",
       " '975',\n",
       " '94',\n",
       " '325',\n",
       " '809',\n",
       " '845',\n",
       " '738',\n",
       " '797',\n",
       " '995',\n",
       " '883',\n",
       " '979',\n",
       " '40',\n",
       " '293',\n",
       " '656',\n",
       " '582',\n",
       " '651',\n",
       " '653',\n",
       " '942',\n",
       " '114',\n",
       " '761',\n",
       " '12',\n",
       " '226',\n",
       " '209',\n",
       " '678',\n",
       " '879',\n",
       " '953',\n",
       " '617',\n",
       " '251',\n",
       " '500',\n",
       " '417',\n",
       " '870',\n",
       " '983',\n",
       " '726',\n",
       " '145',\n",
       " '741',\n",
       " '688',\n",
       " '42',\n",
       " '891',\n",
       " '461',\n",
       " '541',\n",
       " '231',\n",
       " '93',\n",
       " '924',\n",
       " '218',\n",
       " '514',\n",
       " '698',\n",
       " '172',\n",
       " '232',\n",
       " '194',\n",
       " '864',\n",
       " '502',\n",
       " '837',\n",
       " '411',\n",
       " '268',\n",
       " '658',\n",
       " '439',\n",
       " '993',\n",
       " '463',\n",
       " '945',\n",
       " '279',\n",
       " '828',\n",
       " '548',\n",
       " '107',\n",
       " '202',\n",
       " '1014',\n",
       " '736',\n",
       " '876',\n",
       " '400',\n",
       " '530',\n",
       " '22',\n",
       " '8',\n",
       " '971',\n",
       " '354',\n",
       " '78',\n",
       " '148',\n",
       " '525',\n",
       " '1006',\n",
       " '306',\n",
       " '297',\n",
       " '890',\n",
       " '610',\n",
       " '413',\n",
       " '264',\n",
       " '974',\n",
       " '248',\n",
       " '563',\n",
       " '940',\n",
       " '142',\n",
       " '98',\n",
       " '715',\n",
       " '829',\n",
       " '951',\n",
       " '580',\n",
       " '576',\n",
       " '665',\n",
       " '192',\n",
       " '408',\n",
       " '250',\n",
       " '485',\n",
       " '442',\n",
       " '59',\n",
       " '513',\n",
       " '154',\n",
       " '175',\n",
       " '482',\n",
       " '77',\n",
       " '120',\n",
       " '210',\n",
       " '446',\n",
       " '612',\n",
       " '639',\n",
       " '444',\n",
       " '844',\n",
       " '5',\n",
       " '528',\n",
       " '545',\n",
       " '165',\n",
       " '111',\n",
       " '241',\n",
       " '9',\n",
       " '880',\n",
       " '615',\n",
       " '966',\n",
       " '621',\n",
       " '1027',\n",
       " '430',\n",
       " '614',\n",
       " '877',\n",
       " '604',\n",
       " '481',\n",
       " '1044',\n",
       " '421',\n",
       " '679',\n",
       " '414',\n",
       " '660',\n",
       " '1010',\n",
       " '294',\n",
       " '389',\n",
       " '818',\n",
       " '286',\n",
       " '378',\n",
       " '380',\n",
       " '554',\n",
       " '316',\n",
       " '82',\n",
       " '152',\n",
       " '856',\n",
       " '320',\n",
       " '190',\n",
       " '806',\n",
       " '328',\n",
       " '988',\n",
       " '48',\n",
       " '136',\n",
       " '288',\n",
       " '489',\n",
       " '676',\n",
       " '535',\n",
       " '691',\n",
       " '260',\n",
       " '723',\n",
       " '124',\n",
       " '579',\n",
       " '4',\n",
       " '109',\n",
       " '872',\n",
       " '991',\n",
       " '228',\n",
       " '887',\n",
       " '553',\n",
       " '585',\n",
       " '365',\n",
       " '504',\n",
       " '45',\n",
       " '86',\n",
       " '34',\n",
       " '336',\n",
       " '113',\n",
       " '954',\n",
       " '789',\n",
       " '899',\n",
       " '630',\n",
       " '275',\n",
       " '467',\n",
       " '978',\n",
       " '609',\n",
       " '289',\n",
       " '290',\n",
       " '55',\n",
       " '25',\n",
       " '240',\n",
       " '81',\n",
       " '174',\n",
       " '647',\n",
       " '908',\n",
       " '969',\n",
       " '795',\n",
       " '330',\n",
       " '767',\n",
       " '532',\n",
       " '1026',\n",
       " '862',\n",
       " '1039',\n",
       " '38',\n",
       " '379',\n",
       " '573',\n",
       " '287',\n",
       " '1012',\n",
       " '477',\n",
       " '909',\n",
       " '939',\n",
       " '700',\n",
       " '730',\n",
       " '168',\n",
       " '179',\n",
       " '371',\n",
       " '57',\n",
       " '140',\n",
       " '519',\n",
       " '905',\n",
       " '985',\n",
       " '185',\n",
       " '129',\n",
       " '808',\n",
       " '886',\n",
       " '187',\n",
       " '518',\n",
       " '815',\n",
       " '912',\n",
       " '181',\n",
       " '339',\n",
       " '646',\n",
       " '838',\n",
       " '440',\n",
       " '431',\n",
       " '549',\n",
       " '948',\n",
       " '990',\n",
       " '892',\n",
       " '986',\n",
       " '1045',\n",
       " '919',\n",
       " '1048',\n",
       " '162',\n",
       " '350',\n",
       " '399',\n",
       " '298',\n",
       " '1021',\n",
       " '693',\n",
       " '950',\n",
       " '204',\n",
       " '388',\n",
       " '464',\n",
       " '699',\n",
       " '897',\n",
       " '898',\n",
       " '803',\n",
       " '1013',\n",
       " '775',\n",
       " '468',\n",
       " '1009',\n",
       " '284',\n",
       " '655',\n",
       " '227',\n",
       " '760',\n",
       " '412',\n",
       " '108',\n",
       " '402',\n",
       " '1022',\n",
       " '15',\n",
       " '89',\n",
       " '208',\n",
       " '403',\n",
       " '233',\n",
       " '499',\n",
       " '36',\n",
       " '613',\n",
       " '686',\n",
       " '1024',\n",
       " '170',\n",
       " '1032',\n",
       " '160',\n",
       " '427',\n",
       " '561',\n",
       " '127',\n",
       " '861',\n",
       " '643',\n",
       " '871',\n",
       " '410',\n",
       " '215',\n",
       " '830',\n",
       " '622',\n",
       " '944',\n",
       " '91',\n",
       " '1020',\n",
       " '31',\n",
       " '46',\n",
       " '868',\n",
       " '1030',\n",
       " '572',\n",
       " '368',\n",
       " '980',\n",
       " '645',\n",
       " '805',\n",
       " '259',\n",
       " '674',\n",
       " '605',\n",
       " '642',\n",
       " '571',\n",
       " '852',\n",
       " '176',\n",
       " '470',\n",
       " '44',\n",
       " '433',\n",
       " '884',\n",
       " '977',\n",
       " '23',\n",
       " '999',\n",
       " '138',\n",
       " '1008',\n",
       " '602',\n",
       " '970',\n",
       " '393',\n",
       " '695',\n",
       " '717',\n",
       " '904',\n",
       " '759',\n",
       " '798',\n",
       " '649',\n",
       " '863',\n",
       " '390',\n",
       " '24',\n",
       " '2',\n",
       " '84',\n",
       " '352',\n",
       " '667',\n",
       " '538',\n",
       " '957',\n",
       " '599',\n",
       " '457',\n",
       " '956',\n",
       " '133',\n",
       " '733',\n",
       " '274',\n",
       " '475',\n",
       " '623',\n",
       " '100',\n",
       " '673',\n",
       " '537',\n",
       " '526',\n",
       " '540',\n",
       " '568',\n",
       " '56',\n",
       " '566',\n",
       " '529',\n",
       " '406',\n",
       " '606',\n",
       " '118',\n",
       " '835',\n",
       " '206',\n",
       " '587',\n",
       " '292',\n",
       " '724',\n",
       " '994',\n",
       " '373',\n",
       " '312',\n",
       " '366',\n",
       " '205',\n",
       " '87',\n",
       " '804',\n",
       " '246',\n",
       " '755',\n",
       " '225',\n",
       " '512',\n",
       " '376',\n",
       " '494',\n",
       " '893',\n",
       " '419',\n",
       " '381',\n",
       " '982',\n",
       " '249',\n",
       " '874',\n",
       " '1041',\n",
       " '58',\n",
       " '372',\n",
       " '731',\n",
       " '370',\n",
       " '666',\n",
       " '27',\n",
       " '167',\n",
       " '713',\n",
       " '49',\n",
       " '976',\n",
       " '981',\n",
       " '772',\n",
       " '524',\n",
       " '1028',\n",
       " '245',\n",
       " '914',\n",
       " '255',\n",
       " '450',\n",
       " '696',\n",
       " '103',\n",
       " '324',\n",
       " '426',\n",
       " '1038',\n",
       " '407',\n",
       " '506',\n",
       " '480',\n",
       " '244',\n",
       " '65',\n",
       " '462',\n",
       " '710',\n",
       " '881',\n",
       " '533',\n",
       " '727',\n",
       " '340',\n",
       " '704',\n",
       " '342',\n",
       " '839',\n",
       " '716',\n",
       " '744',\n",
       " '131',\n",
       " '68',\n",
       " '866',\n",
       " '543',\n",
       " '593',\n",
       " '734',\n",
       " '382',\n",
       " '517',\n",
       " '616',\n",
       " '836',\n",
       " '349',\n",
       " '341',\n",
       " '743',\n",
       " '683',\n",
       " '973',\n",
       " '335',\n",
       " '198',\n",
       " '385',\n",
       " '418',\n",
       " '28',\n",
       " '452',\n",
       " '498',\n",
       " '627',\n",
       " '894',\n",
       " '943',\n",
       " '344',\n",
       " '207',\n",
       " '465',\n",
       " '64',\n",
       " '921',\n",
       " '364',\n",
       " '774',\n",
       " '960',\n",
       " '569',\n",
       " '534',\n",
       " '471',\n",
       " '314',\n",
       " '577',\n",
       " '361',\n",
       " '671',\n",
       " '989',\n",
       " '448',\n",
       " '777',\n",
       " '619',\n",
       " '560',\n",
       " '333',\n",
       " '253',\n",
       " '451',\n",
       " '709',\n",
       " '281',\n",
       " '466',\n",
       " '586',\n",
       " '648',\n",
       " '122',\n",
       " '935',\n",
       " '827',\n",
       " '75',\n",
       " '558',\n",
       " '495',\n",
       " '147',\n",
       " '820',\n",
       " '1043',\n",
       " '223',\n",
       " '200',\n",
       " '1015',\n",
       " '80',\n",
       " '237',\n",
       " '473',\n",
       " '32',\n",
       " '634',\n",
       " '677',\n",
       " '791',\n",
       " '441',\n",
       " '802',\n",
       " '728',\n",
       " '313',\n",
       " '159',\n",
       " '811',\n",
       " '434',\n",
       " '184',\n",
       " '263',\n",
       " '432',\n",
       " '754',\n",
       " '822',\n",
       " '807',\n",
       " '636',\n",
       " '813',\n",
       " '763',\n",
       " '703',\n",
       " '1023',\n",
       " '575',\n",
       " '304',\n",
       " '770',\n",
       " '1046',\n",
       " '156',\n",
       " '906',\n",
       " '318',\n",
       " '321',\n",
       " '675',\n",
       " '762',\n",
       " '449',\n",
       " '188',\n",
       " '694',\n",
       " '550',\n",
       " '817',\n",
       " '781',\n",
       " '920',\n",
       " '296',\n",
       " '624',\n",
       " '941',\n",
       " '952',\n",
       " '258',\n",
       " '144',\n",
       " '1029',\n",
       " '112',\n",
       " '270',\n",
       " '746',\n",
       " '157',\n",
       " '961',\n",
       " '708',\n",
       " '261',\n",
       " '343',\n",
       " '635',\n",
       " '895',\n",
       " '968',\n",
       " '764',\n",
       " '97',\n",
       " '574',\n",
       " '1004',\n",
       " '177',\n",
       " '486',\n",
       " '458',\n",
       " '415',\n",
       " '681',\n",
       " '1035',\n",
       " '780',\n",
       " '1017',\n",
       " '1047',\n",
       " '283',\n",
       " '687',\n",
       " '885',\n",
       " '199',\n",
       " '735',\n",
       " '938',\n",
       " '309',\n",
       " '278',\n",
       " '322',\n",
       " '397',\n",
       " '104',\n",
       " '888',\n",
       " '367',\n",
       " '395',\n",
       " '964',\n",
       " '7',\n",
       " '670',\n",
       " '581',\n",
       " '243',\n",
       " '544',\n",
       " '180',\n",
       " '932',\n",
       " '163',\n",
       " '690',\n",
       " '186',\n",
       " '21',\n",
       " '295',\n",
       " '345',\n",
       " '387',\n",
       " '17',\n",
       " '718',\n",
       " '594',\n",
       " '252',\n",
       " '959',\n",
       " '992',\n",
       " '311',\n",
       " '3',\n",
       " '497',\n",
       " '149',\n",
       " '578',\n",
       " '882',\n",
       " '300',\n",
       " '182',\n",
       " '911',\n",
       " '398',\n",
       " '171',\n",
       " '536',\n",
       " '632',\n",
       " '273',\n",
       " '801',\n",
       " '765',\n",
       " '915',\n",
       " '510',\n",
       " '1019',\n",
       " '589',\n",
       " '1036',\n",
       " '126',\n",
       " '236',\n",
       " '611',\n",
       " '631',\n",
       " '607',\n",
       " '509',\n",
       " '234',\n",
       " '842',\n",
       " '542',\n",
       " '51',\n",
       " '348',\n",
       " '742',\n",
       " '628',\n",
       " '1',\n",
       " '115',\n",
       " '771',\n",
       " '422',\n",
       " '447',\n",
       " '965',\n",
       " '60',\n",
       " '363',\n",
       " '598',\n",
       " '896',\n",
       " '1037',\n",
       " '515',\n",
       " '949',\n",
       " '96',\n",
       " '214',\n",
       " '596',\n",
       " '503',\n",
       " '925',\n",
       " '600',\n",
       " '469',\n",
       " '50',\n",
       " '166',\n",
       " '396',\n",
       " '20',\n",
       " '392',\n",
       " '662',\n",
       " '269',\n",
       " '824',\n",
       " '556',\n",
       " '592',\n",
       " '668',\n",
       " '955',\n",
       " '487',\n",
       " '135',\n",
       " '216',\n",
       " '384',\n",
       " '784',\n",
       " '220',\n",
       " '889',\n",
       " '963',\n",
       " '117',\n",
       " '747',\n",
       " '758',\n",
       " '996',\n",
       " '901',\n",
       " '13',\n",
       " '751',\n",
       " '454',\n",
       " '946',\n",
       " '928',\n",
       " '657',\n",
       " '618',\n",
       " '239',\n",
       " '597',\n",
       " '823',\n",
       " '854',\n",
       " '516',\n",
       " '539',\n",
       " '570',\n",
       " '706',\n",
       " '222',\n",
       " '936',\n",
       " '843',\n",
       " '242',\n",
       " '203',\n",
       " '30',\n",
       " '778',\n",
       " '19',\n",
       " '790',\n",
       " '1040',\n",
       " '565',\n",
       " '684',\n",
       " '831',\n",
       " '865',\n",
       " '374',\n",
       " '588',\n",
       " '456',\n",
       " '308',\n",
       " '1042',\n",
       " '423',\n",
       " '11',\n",
       " '66',\n",
       " '855',\n",
       " '638',\n",
       " '326',\n",
       " '987',\n",
       " '783',\n",
       " '875',\n",
       " '773',\n",
       " '301',\n",
       " '195',\n",
       " '401',\n",
       " '873',\n",
       " '0',\n",
       " '134',\n",
       " '712',\n",
       " '74',\n",
       " '332',\n",
       " '453',\n",
       " '479',\n",
       " '721',\n",
       " '329',\n",
       " '511',\n",
       " '151',\n",
       " '520',\n",
       " '1034',\n",
       " '832',\n",
       " '213',\n",
       " '357',\n",
       " '474',\n",
       " '507',\n",
       " '1000',\n",
       " '224',\n",
       " '416',\n",
       " '90',\n",
       " '178',\n",
       " '697',\n",
       " '394',\n",
       " '814',\n",
       " '386',\n",
       " '41',\n",
       " '201',\n",
       " '812',\n",
       " '785',\n",
       " '850',\n",
       " '620',\n",
       " '130',\n",
       " '654',\n",
       " '26',\n",
       " '164',\n",
       " '72',\n",
       " '860',\n",
       " '779',\n",
       " '907',\n",
       " '29',\n",
       " '221',\n",
       " '338',\n",
       " '420',\n",
       " '1007',\n",
       " '788',\n",
       " '583',\n",
       " '1018',\n",
       " '488',\n",
       " '672',\n",
       " '191',\n",
       " '305',\n",
       " '291',\n",
       " '377',\n",
       " '972',\n",
       " '141',\n",
       " '719',\n",
       " '331',\n",
       " '18',\n",
       " '230',\n",
       " '937',\n",
       " '1002',\n",
       " '547',\n",
       " '725',\n",
       " '849',\n",
       " '661',\n",
       " '739',\n",
       " '47',\n",
       " '271',\n",
       " '238',\n",
       " '552',\n",
       " '659',\n",
       " '878',\n",
       " '256',\n",
       " '1003',\n",
       " '337',\n",
       " '323',\n",
       " '796',\n",
       " '327',\n",
       " '92',\n",
       " '125',\n",
       " '555',\n",
       " '436',\n",
       " '757',\n",
       " '633',\n",
       " '916',\n",
       " '711',\n",
       " '490',\n",
       " '383',\n",
       " '105',\n",
       " '493',\n",
       " '664',\n",
       " '1005',\n",
       " '10',\n",
       " '692',\n",
       " '73',\n",
       " '782',\n",
       " '652',\n",
       " '310',\n",
       " '193',\n",
       " '834',\n",
       " '701',\n",
       " '6',\n",
       " '95',\n",
       " '276',\n",
       " '705',\n",
       " '484',\n",
       " '584',\n",
       " '476',\n",
       " '83',\n",
       " '501',\n",
       " '478',\n",
       " '435',\n",
       " '266',\n",
       " '910',\n",
       " '1025',\n",
       " '132',\n",
       " '360',\n",
       " '794',\n",
       " '682',\n",
       " '39',\n",
       " '99',\n",
       " '590',\n",
       " '603',\n",
       " '768',\n",
       " '934',\n",
       " '106',\n",
       " '196',\n",
       " '967',\n",
       " '52',\n",
       " '491',\n",
       " '505',\n",
       " '62',\n",
       " '663',\n",
       " '1031',\n",
       " '841',\n",
       " '334',\n",
       " '559',\n",
       " '189',\n",
       " '825',\n",
       " '1011',\n",
       " '846',\n",
       " '564',\n",
       " '143',\n",
       " '947',\n",
       " '158',\n",
       " '923',\n",
       " '212',\n",
       " '153',\n",
       " '522',\n",
       " '748',\n",
       " '848',\n",
       " '262',\n",
       " '16',\n",
       " '211',\n",
       " '302',\n",
       " '496',\n",
       " '123',\n",
       " '443',\n",
       " '608',\n",
       " '405',\n",
       " '267',\n",
       " '455',\n",
       " '984',\n",
       " '257',\n",
       " '637',\n",
       " '169',\n",
       " '591',\n",
       " '429',\n",
       " '930',\n",
       " '33',\n",
       " '997',\n",
       " '527',\n",
       " '714',\n",
       " '840',\n",
       " '720',\n",
       " '277',\n",
       " '61',\n",
       " '347',\n",
       " '567',\n",
       " '644',\n",
       " '786',\n",
       " '161',\n",
       " '76',\n",
       " '650',\n",
       " '857',\n",
       " '902',\n",
       " '929',\n",
       " '931',\n",
       " '425',\n",
       " '523',\n",
       " '998',\n",
       " '749',\n",
       " '900',\n",
       " '756',\n",
       " '303',\n",
       " '437',\n",
       " '438',\n",
       " '43',\n",
       " '101',\n",
       " '729',\n",
       " '689',\n",
       " '317',\n",
       " '640',\n",
       " '1033',\n",
       " '353',\n",
       " '359',\n",
       " '1016',\n",
       " '833',\n",
       " '155',\n",
       " '859',\n",
       " '85',\n",
       " '79',\n",
       " '826',\n",
       " '67',\n",
       " '685',\n",
       " '272',\n",
       " '702',\n",
       " '265',\n",
       " '707',\n",
       " '918',\n",
       " '14',\n",
       " '70',\n",
       " '307',\n",
       " '793',\n",
       " '847',\n",
       " '816',\n",
       " '35',\n",
       " '933',\n",
       " '280',\n",
       " '922',\n",
       " '521',\n",
       " '139',\n",
       " '197',\n",
       " '128',\n",
       " '351',\n",
       " '445',\n",
       " '601',\n",
       " '358',\n",
       " '562',\n",
       " '404',\n",
       " '625',\n",
       " '867',\n",
       " ...}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dd98c52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chatgpt_target_one-shot_outputs.json | Accuracy: 0.43 | F1: 0.41\n",
      "chatgpt_all_one-shot_outputs.json | Accuracy: 0.44 | F1: 0.42\n",
      "chatgpt_target_ten-shot_outputs.json | Accuracy: 0.46 | F1: 0.44\n",
      "chatgpt_all_five-shot_outputs.json | Accuracy: 0.51 | F1: 0.52\n",
      "chatgpt_all_ten-shot_outputs.json | Accuracy: 0.51 | F1: 0.52\n",
      "chatgpt_target_zero-shot_outputs.json | Accuracy: 0.37 | F1: 0.29\n",
      "chatgpt_early_target_five-shot_outputs.json | Accuracy: 0.51 | F1: 0.52\n",
      "chatgpt_all_zero-shot_outputs.json | Accuracy: 0.40 | F1: 0.36\n",
      "chatgpt_target_later_zero-shot_outputs.json | Accuracy: 0.40 | F1: 0.36\n",
      "chatgpt_target_later_one-shot_outputs.json | Accuracy: 0.43 | F1: 0.41\n",
      "chatgpt_early_target_zero-shot_outputs.json | Accuracy: 0.40 | F1: 0.34\n",
      "chatgpt_target_later_ten-shot_outputs.json | Accuracy: 0.47 | F1: 0.47\n",
      "chatgpt_early_target_ten-shot_outputs.json | Accuracy: 0.51 | F1: 0.51\n",
      "chatgpt_early_target_one-shot_outputs.json | Accuracy: 0.44 | F1: 0.41\n",
      "chatgpt_target_later_five-shot_outputs.json | Accuracy: 0.49 | F1: 0.49\n",
      "chatgpt_target_five-shot_outputs.json | Accuracy: 0.45 | F1: 0.45\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "for output_filename in os.listdir(\"output/results/\"):\n",
    "    \n",
    "    if 'chatgpt' not in output_filename:\n",
    "        continue\n",
    "        \n",
    "    preds = []\n",
    "    output_filepath = os.path.join(\"output/results/\", output_filename)\n",
    "    with open(output_filepath, 'r') as file:\n",
    "        lines = file.read().splitlines()\n",
    "        for line in lines:\n",
    "            item = json.loads(line)\n",
    "            content = item['choices'][0]['message']['content']\n",
    "            if content.startswith('1') or 'Yes' in content:\n",
    "                preds.append('Yes')\n",
    "            elif content.startswith('2') or 'No' in content:\n",
    "                preds.append('No')\n",
    "\n",
    "    labels = test_samples['label']\n",
    "    try:\n",
    "        results = classification_report(labels, preds, output_dict=True)\n",
    "    except:\n",
    "        print(output_filename, len(preds), len(labels))\n",
    "        continue\n",
    "    print(f\"{output_filename} | Accuracy: {results['accuracy']:.2f} | F1: {results['weighted avg']['f1-score']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ebd1aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "956"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b189fff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_filepath, 'r') as file:\n",
    "    lines = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa143bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb40669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1331e351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b5254e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b4c589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
